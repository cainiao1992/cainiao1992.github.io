<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://cainiao1992.github.io</id>
    <title>èœé¸Ÿçš„ç¬”è®°</title>
    <updated>2023-11-25T04:05:23.698Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://cainiao1992.github.io"/>
    <link rel="self" href="https://cainiao1992.github.io/atom.xml"/>
    <subtitle>æ¸©æ•…è€ŒçŸ¥æ–°</subtitle>
    <logo>https://cainiao1992.github.io/images/avatar.png</logo>
    <icon>https://cainiao1992.github.io/favicon.ico</icon>
    <rights>All rights reserved 2023, èœé¸Ÿçš„ç¬”è®°</rights>
    <entry>
        <title type="html"><![CDATA[OpenSSH ç¬”è®°]]></title>
        <id>https://cainiao1992.github.io/post/openssh/</id>
        <link href="https://cainiao1992.github.io/post/openssh/">
        </link>
        <updated>2023-09-01T08:31:23.000Z</updated>
        <content type="html"><![CDATA[<p>é…ç½®å…å¯†ç™»å½•</p>
<pre><code class="language-shell"># åˆ›å»ºSSHå¯†é’¥å¯¹ã€‚
ssh-keygen -t rsa -b 4096

# è·å–SSHå…¬é’¥ã€‚
cat ~/.ssh/id_rsa.pub

# é…ç½®å…å¯†ç™»å½•çš„æœåŠ¡å™¨ä¸»æœºã€‚
ssh-copy-id root@uing.vip
``

é…ç½® root ç”¨æˆ·ç™»å½•
``` shell
vi /etc/ssh/sshd_config
# root ç”¨æˆ·ç™»å½•
# prohibit-password / without-password:ç¦æ­¢å¯†ç ç™»å½• root
# yes: å…è®¸ä½¿ç”¨å¯†ç ç™»å½• root
# no: ç¦æ­¢ç™»å½• root
# PermitRootLogin yes
# èƒ½å¦ä½¿ç”¨å¯†ç ç™»å½•SSH (åŒ…æ‹¬å…¶å®ƒç”¨æˆ·)
# PasswordAuthentication no

echo &quot;PermitRootLogin yes&quot; | sudo tee /etc/ssh/sshd_config
systemctl restart sshd
</code></pre>
<p>è§£é™¤ï¼ˆæ¸…é™¤ï¼‰ä¿¡ä»»ä¸»æœºå…¬é’¥</p>
<pre><code class="language-shell">ssh-keygen -R uing.vip
</code></pre>
<h1 id="ssh-è·³æ¿æœºè¿æ¥æ–¹æ³•">SSH è·³æ¿æœºè¿æ¥æ–¹æ³•</h1>
<pre><code class="language-bash">ssh username@ç›®æ ‡æœºå™¨IP -p 22 -J username@è·³æ¿æœºIP:22
</code></pre>
<p>äº§ç”Ÿ64bitéšæœºæ•°</p>
<pre><code class="language-bash">openssl rand -base64 64
</code></pre>
<hr>
<h3 id="é‡åˆ°çš„é—®é¢˜">é‡åˆ°çš„é—®é¢˜</h3>
<p>ä½¿ç”¨è¿‡æ—¶çš„å¯†é’¥ç®—æ³•</p>
<pre><code>Unable to negotiate with 192.168.2.21 port 22: no matching host key type found. Their offer: ssh-rsa,ssh-dss
</code></pre>
<p>è§£å†³</p>
<pre><code class="language-shell"># å¢åŠ  -oHostKeyAlgorithms=+ssh-dss é€‰é¡¹
ssh -oHostKeyAlgorithms=+ssh-dss root@192.168.2.21
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Caddy2 - èƒ½å¤Ÿè‡ªåŠ¨ç”³è¯·è¯ä¹¦çš„ HTTPS/HTTP æœåŠ¡å™¨]]></title>
        <id>https://cainiao1992.github.io/post/caddy2/</id>
        <link href="https://cainiao1992.github.io/post/caddy2/">
        </link>
        <updated>2023-08-29T13:54:39.000Z</updated>
        <content type="html"><![CDATA[<h2 id="è‡ªåŠ¨https">è‡ªåŠ¨HTTPS</h2>
<p>å½“ç¬¦åˆä¸‹é¢ä¸€äº›åˆç†çš„æ ‡å‡†æ—¶ï¼ŒCaddyä¼šè‡ªåŠ¨ä¸ºæ‰€æœ‰ç«™ç‚¹å¯ç”¨HTTPS:</p>
<ul>
<li>ä¸»æœºå
<ul>
<li>ä¸ä¸ºç©º</li>
<li>ä¸æ˜¯localhost</li>
<li>ä¸æ˜¯ä¸€ä¸ªIPåœ°å€</li>
<li>ä¸è¶…è¿‡ä¸€ä¸ªé€šé…ç¬¦ï¼ˆ*ï¼‰</li>
<li>é€šé…ç¬¦å¿…é¡»æ˜¯æœ€å·¦è¾¹çš„æ ‡ç­¾</li>
</ul>
</li>
<li>æ²¡æœ‰æ˜¾å¼æŒ‡å®šç«¯å£ä¸º80</li>
<li>æ²¡æœ‰æ˜¾å¼æŒ‡å®šä½¿ç”¨httpåè®®</li>
<li>TLSæ²¡æœ‰åœ¨ç«™ç‚¹çš„å®šä¹‰ä¸­è¢«å…³é—­</li>
<li>ä¸æ˜¯ä½ è‡ªå·±æä¾›çš„è¯ä¹¦å’Œå¯†é’¥</li>
<li>Caddyèƒ½å¤Ÿç»‘å®šåˆ°ç«¯å£80å’Œ443ï¼ˆé™¤éä½¿ç”¨DNSéªŒè¯ï¼‰</li>
</ul>
<p>Caddyè¿˜ä¼šå°†æ‰€æœ‰HTTPè¯·æ±‚é‡å®šå‘åˆ°ä¸HTTPSå¯¹åº”çš„åœ°å€ï¼Œåªè¦Caddyfileä¸­æ²¡æœ‰å®šä¹‰ä¸»æœºåçš„çº¯æ–‡æœ¬å˜ä½“ã€‚</p>
<hr>
<h2 id="å®‰è£…éƒ¨ç½²">å®‰è£…éƒ¨ç½²</h2>
<ul>
<li>docker-compose.yml</li>
</ul>
<pre><code class="language-yaml">version: &quot;3&quot;

services:
  caddy:
    container_name: caddy
    image: caddy:alpine
    restart: unless-stopped
    ports:
      - &quot;80:80&quot;
      - &quot;80:80/udp&quot;
      - &quot;443:443&quot;
      - &quot;443:443/udp&quot;
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile
      - ./caddy/:/data/caddy/
</code></pre>
<ul>
<li>Caddyfile</li>
</ul>
<pre><code class="language-Caddyfile">:80 {
  redir https://{host}{uri}
}

uing.vip {
  log {
    output stdout
    format console
    level  ERROR
  }
  root * /var/www/uing.vip
  handle_errors {
    rewrite * /404.html
    file_server
  }
  file_server
}

gitea.uing.vip {
  log {
    output stdout
    format console
    level  ERROR
  }
  reverse_proxy gitea:3000
}
</code></pre>
<h2 id="å¦‚æœéœ€è¦æ¥å…¥-cloudflare-cdn-ä¸Š">å¦‚æœéœ€è¦æ¥å…¥ Cloudflare CDN ä¸Š</h2>
<ol>
<li>æ‰“å¼€ https://dash.cloudflare.com/ æ³¨å†Œç™»å½•</li>
<li>æ·»åŠ ç½‘ç«™ï¼Œæ›´æ”¹åŸŸåçš„ DNS</li>
<li>æ‰“å¼€ https://dash.cloudflare.com/profile/api-tokens</li>
<li>API ä»¤ç‰Œ -&gt; åˆ›å»º API ä»¤ç‰Œ -&gt; ç¼–è¾‘åŒºåŸŸ DNS -&gt; é€‰æ‹©æ¨¡æ¿ -&gt; åŒºåŸŸèµ„æº -&gt; å¯¹åº”ç½‘ç«™</li>
<li>è·å–åˆ°çš„API KEY -&gt; docker-compose.yml -&gt; caddy å®¹å™¨ -&gt; æ›¿æ¢ CF_API_TOKEN ç¯å¢ƒå˜é‡ -&gt; æ›¿æ¢ DOMAIN ç¯å¢ƒå˜é‡ï¼ˆä¹Ÿå¯ä»¥æ˜¯äºŒçº§æˆ–ä¸‰çº§åŸŸåï¼‰</li>
<li>https://dash.cloudflare.com -&gt; å¯¹åº”ç½‘ç«™</li>
<li>SSL/TLS -&gt; æºæœåŠ¡å™¨ -&gt; æºè¯ä¹¦ -&gt;  ç»è¿‡èº«ä»½éªŒè¯çš„æºæœåŠ¡å™¨æ‹‰å– -&gt; æ‰“å¼€</li>
<li>SSL/TLS -&gt; æ¦‚è¿° -&gt; æ‚¨çš„ SSL/TLS åŠ å¯†æ¨¡å¼ä¸º -&gt; å®Œå…¨ï¼ˆä¸¥æ ¼ï¼‰</li>
</ol>
<ul>
<li>docker-compose.yml</li>
</ul>
<pre><code class="language-yaml">version: &quot;3&quot;
services:
  caddy:
    container_name: caddy
    build: 
      dockerfile: ./caddy-cloudflare-Dockerfile
    restart: unless-stopped
    depends_on:
      - sing-box
      # - subconverter
    ports:
      - &quot;80:80&quot;
      - &quot;80:80/udp&quot;
      - &quot;443:443&quot;
      - &quot;443:443/udp&quot;
    environment:
      - CF_API_TOKEN=XXX
      - DOMAIN=XXX
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile
      - ./caddy:/data/caddy
</code></pre>
<ul>
<li>Caddyfile</li>
</ul>
<pre><code class="language-Caddyfile">{env.DOMAIN} {
  log {
    output stdout
    format console
    level  ERROR
  }
  reverse_proxy gitea:3000
}
</code></pre>
<ul>
<li>caddy-cloudflare-Dockerfile</li>
</ul>
<pre><code class="language-Dockerfile">FROM caddy:builder-alpine AS builder
RUN xcaddy build --with github.com/caddy-dns/cloudflare

FROM caddy:alpine
COPY --from=builder /usr/bin/caddy /usr/bin/caddy
</code></pre>
<h2 id="ç›¸å…³è¿æ¥">ç›¸å…³è¿æ¥</h2>
<ul>
<li><a href="https://caddyserver.com/docs">Caddy Docs</a></li>
<li><a href="https://caddy2.dengxiaolong.com/docs/">Caddy v2ä¸­æ–‡æ–‡æ¡£</a></li>
<li><a href="https://dengxiaolong.com/caddy/zh/">Caddyä¸­æ–‡æ–‡æ¡£(V1)</a></li>
<li><a href="https://github.com/caddy-dns/cloudflare">Cloudflare module for Caddy</a></li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Harbor - ç§æœ‰åŒ–å®¹å™¨ä»“åº“]]></title>
        <id>https://cainiao1992.github.io/post/harbor/</id>
        <link href="https://cainiao1992.github.io/post/harbor/">
        </link>
        <updated>2023-08-29T11:26:12.000Z</updated>
        <content type="html"><![CDATA[<ul>
<li>docker-compose.yml</li>
</ul>
<pre><code class="language-yaml">version: &quot;3&quot;

services:
  caddy:
    container_name: caddy
    image: caddy:alpine
    restart: unless-stopped
    ports:
      - &quot;80:80&quot;
      - &quot;80:80/udp&quot;
      - &quot;443:443&quot;
      - &quot;443:443/udp&quot;
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile
  harbor:
    container_name: harbor
    build:
      dockerfile: ./harbor-Dockerfile
    privileged: true
    volumes:
      - ./harbor/data:/data
      - ./harbor/harbor:/opt/harbor
</code></pre>
<ul>
<li>Caddyfile</li>
</ul>
<pre><code class="language-Caddyfile">registry.uing.vip {
  log {
    output stdout
    format console
    level  ERROR
  }
  reverse_proxy harbor:9000
}
</code></pre>
<ul>
<li>harbor-Dockerfile</li>
</ul>
<pre><code class="language-Dockerfile">FROM docker:dind
MAINTAINER cainiao &lt;565499699@qq.com&gt;

COPY harbor/harbor-entrypoint.sh /usr/local/bin/harbor-entrypoint.sh
COPY harbor/supervisord.conf /etc/supervisord.conf
COPY harbor/harbor.yml /harbor.yml

RUN apk add --no-cache supervisor &amp;&amp; chmod a+x /usr/local/bin/harbor-entrypoint.sh

ENTRYPOINT [&quot;/usr/bin/supervisord&quot;, &quot;-c&quot;, &quot;/etc/supervisord.conf&quot;]
</code></pre>
<ul>
<li>harbor/harbor-entrypoint.sh</li>
</ul>
<pre><code class="language-bash">#!/bin/sh

if [ -f /opt/harbor/docker-compose.yml ]; then
    cd /opt/harbor/ &amp;&amp; docker-compose up
else
    cd /opt
    apk add --no-cache --virtual .build_tools ncurses bash wget
    
    wget -O harbor-online-installer.tgz \
        https://github.com/goharbor/harbor/releases/download/v2.8.4/harbor-online-installer-v2.8.4.tgz \
        &amp;&amp; tar xzf harbor-online-installer.tgz \
        &amp;&amp; rm -f harbor-online-installer.tgz
    
    cd /opt/harbor
    
    cp -f /harbor.yml .
    bash ./install.sh

    apk del .build_tools
    
    docker-compose logs -f
fi
</code></pre>
<ul>
<li>harbor/supervisord.conf</li>
</ul>
<pre><code class="language-ini">[supervisord]
nodaemon=true

[program:dockerd]
command=/usr/local/bin/dockerd-entrypoint.sh
stdout_logfile=/dev/stdout
stdout_logfile_maxbytes=0
stderr_logfile=/dev/stderr
stderr_logfile_maxbytes=0
autostar=true
autorestart=true

[program:harbor]
command=/usr/local/bin/harbor-entrypoint.sh
stdout_logfile=/dev/stdout
stdout_logfile_maxbytes=0
stderr_logfile=/dev/stderr
stderr_logfile_maxbytes=0
autostar=true
autorestart=true
startsecs=3
</code></pre>
<ul>
<li>harbor/harbor.yml</li>
</ul>
<pre><code class="language-yaml"># Configuration file of Harbor

# The IP address or hostname to access admin UI and registry service.
# DO NOT use localhost or 127.0.0.1, because Harbor needs to be accessed by external clients.
hostname: registry.uing.vip

# http related config
http:
  # port for http, default is 80. If https enabled, this port will redirect to https port
  port: 80

# # https related config
# https:
#   # https port for harbor, default is 443
#   port: 443
#   # The path of cert and key files for nginx
#   certificate: /your/certificate/path
#   private_key: /your/private/key/path


# # Uncomment following will enable tls communication between all harbor components
# internal_tls:
#   # set enabled to true means internal tls is enabled
#   enabled: true
#   # put your cert and key files on dir
#   dir: /etc/harbor/tls/internal
#   # enable strong ssl ciphers (default: false)
#   strong_ssl_ciphers: false

# Uncomment external_url if you want to enable external proxy
# And when it enabled the hostname will no longer used
external_url: https://registry.uing.vip

# The initial password of Harbor admin
# It only works in first time to install harbor
# Remember Change the admin password from UI after launching Harbor.
harbor_admin_password: XXXXXXXXXXXX

# Harbor DB configuration
database:
  # The password for the root user of Harbor DB. Change this before any production use.
  password: root123
  # The maximum number of connections in the idle connection pool. If it &lt;=0, no idle connections are retained.
  max_idle_conns: 100
  # The maximum number of open connections to the database. If it &lt;= 0, then there is no limit on the number of open connections.
  # Note: the default number of connections is 1024 for postgres of harbor.
  max_open_conns: 900
  # The maximum amount of time a connection may be reused. Expired connections may be closed lazily before reuse. If it &lt;= 0, connections are not closed due to a connection's age.
  # The value is a duration string. A duration string is a possibly signed sequence of decimal numbers, each with optional fraction and a unit suffix, such as &quot;300ms&quot;, &quot;-1.5h&quot; or &quot;2h45m&quot;. Valid time units are &quot;ns&quot;, &quot;us&quot; (or &quot;Âµs&quot;), &quot;ms&quot;, &quot;s&quot;, &quot;m&quot;, &quot;h&quot;.
  conn_max_lifetime: 5m
  # The maximum amount of time a connection may be idle. Expired connections may be closed lazily before reuse. If it &lt;= 0, connections are not closed due to a connection's idle time.
  # The value is a duration string. A duration string is a possibly signed sequence of decimal numbers, each with optional fraction and a unit suffix, such as &quot;300ms&quot;, &quot;-1.5h&quot; or &quot;2h45m&quot;. Valid time units are &quot;ns&quot;, &quot;us&quot; (or &quot;Âµs&quot;), &quot;ms&quot;, &quot;s&quot;, &quot;m&quot;, &quot;h&quot;.
  conn_max_idle_time: 0

# The default data volume
data_volume: /data

# Harbor Storage settings by default is using /data dir on local filesystem
# Uncomment storage_service setting If you want to using external storage
# storage_service:
#   # ca_bundle is the path to the custom root ca certificate, which will be injected into the truststore
#   # of registry's containers.  This is usually needed when the user hosts a internal storage with self signed certificate.
#   ca_bundle:

#   # storage backend, default is filesystem, options include filesystem, azure, gcs, s3, swift and oss
#   # for more info about this configuration please refer https://docs.docker.com/registry/configuration/
#   filesystem:
#     maxthreads: 100
#   # set disable to true when you want to disable registry redirect
#   redirect:
#     disable: false

# Trivy configuration
#
# Trivy DB contains vulnerability information from NVD, Red Hat, and many other upstream vulnerability databases.
# It is downloaded by Trivy from the GitHub release page https://github.com/aquasecurity/trivy-db/releases and cached
# in the local file system. In addition, the database contains the update timestamp so Trivy can detect whether it
# should download a newer version from the Internet or use the cached one. Currently, the database is updated every
# 12 hours and published as a new release to GitHub.
trivy:
  # ignoreUnfixed The flag to display only fixed vulnerabilities
  ignore_unfixed: false
  # skipUpdate The flag to enable or disable Trivy DB downloads from GitHub
  #
  # You might want to enable this flag in test or CI/CD environments to avoid GitHub rate limiting issues.
  # If the flag is enabled you have to download the `trivy-offline.tar.gz` archive manually, extract `trivy.db` and
  # `metadata.json` files and mount them in the `/home/scanner/.cache/trivy/db` path.
  skip_update: false
  #
  # The offline_scan option prevents Trivy from sending API requests to identify dependencies.
  # Scanning JAR files and pom.xml may require Internet access for better detection, but this option tries to avoid it.
  # For example, the offline mode will not try to resolve transitive dependencies in pom.xml when the dependency doesn't
  # exist in the local repositories. It means a number of detected vulnerabilities might be fewer in offline mode.
  # It would work if all the dependencies are in local.
  # This option doesn't affect DB download. You need to specify &quot;skip-update&quot; as well as &quot;offline-scan&quot; in an air-gapped environment.
  offline_scan: false
  #
  # Comma-separated list of what security issues to detect. Possible values are `vuln`, `config` and `secret`. Defaults to `vuln`.
  security_check: vuln
  #
  # insecure The flag to skip verifying registry certificate
  insecure: false
  # github_token The GitHub access token to download Trivy DB
  #
  # Anonymous downloads from GitHub are subject to the limit of 60 requests per hour. Normally such rate limit is enough
  # for production operations. If, for any reason, it's not enough, you could increase the rate limit to 5000
  # requests per hour by specifying the GitHub access token. For more details on GitHub rate limiting please consult
  # https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting
  #
  # You can create a GitHub token by following the instructions in
  # https://help.github.com/en/github/authenticating-to-github/creating-a-personal-access-token-for-the-command-line
  #
  # github_token: xxx

jobservice:
  # Maximum number of job workers in job service
  max_job_workers: 10
  # The jobLoggers backend name, only support &quot;STD_OUTPUT&quot;, &quot;FILE&quot; and/or &quot;DB&quot;
  job_loggers:
    - STD_OUTPUT
    - FILE
    # - DB
  # The jobLogger sweeper duration (ignored if `jobLogger` is `stdout`)
  logger_sweeper_duration: 1 #days

notification:
  # Maximum retry count for webhook job
  webhook_job_max_retry: 3
  # HTTP client timeout for webhook job
  webhook_job_http_client_timeout: 3 #seconds

# Log configurations
log:
  # options are debug, info, warning, error, fatal
  level: info
  # configs for logs in local storage
  local:
    # Log files are rotated log_rotate_count times before being removed. If count is 0, old versions are removed rather than rotated.
    rotate_count: 50
    # Log files are rotated only if they grow bigger than log_rotate_size bytes. If size is followed by k, the size is assumed to be in kilobytes.
    # If the M is used, the size is in megabytes, and if G is used, the size is in gigabytes. So size 100, size 100k, size 100M and size 100G
    # are all valid.
    rotate_size: 200M
    # The directory on your host that store log
    location: /var/log/harbor

  # Uncomment following lines to enable external syslog endpoint.
  # external_endpoint:
  #   # protocol used to transmit log to external endpoint, options is tcp or udp
  #   protocol: tcp
  #   # The host of external endpoint
  #   host: localhost
  #   # Port of external endpoint
  #   port: 5140

#This attribute is for migrator to detect the version of the .cfg file, DO NOT MODIFY!
_version: 2.9.0

# Uncomment external_database if using external database.
# external_database:
#   harbor:
#     host: harbor_db_host
#     port: harbor_db_port
#     db_name: harbor_db_name
#     username: harbor_db_username
#     password: harbor_db_password
#     ssl_mode: disable
#     max_idle_conns: 2
#     max_open_conns: 0

# Uncomment redis if need to customize redis db
# redis:
#   # db_index 0 is for core, it's unchangeable
#   # registry_db_index: 1
#   # jobservice_db_index: 2
#   # trivy_db_index: 5
#   # it's optional, the db for harbor business misc, by default is 0, uncomment it if you want to change it.
#   # harbor_db_index: 6
#   # it's optional, the db for harbor cache layer, by default is 0, uncomment it if you want to change it.
#   # cache_db_index: 7

# Uncomment redis if need to customize redis db
# redis:
#   # db_index 0 is for core, it's unchangeable
#   # registry_db_index: 1
#   # jobservice_db_index: 2
#   # trivy_db_index: 5
#   # it's optional, the db for harbor business misc, by default is 0, uncomment it if you want to change it.
#   # harbor_db_index: 6
#   # it's optional, the db for harbor cache layer, by default is 0, uncomment it if you want to change it.
#   # cache_layer_db_index: 7

# Uncomment external_redis if using external Redis server
# external_redis:
#   # support redis, redis+sentinel
#   # host for redis: &lt;host_redis&gt;:&lt;port_redis&gt;
#   # host for redis+sentinel:
#   #  &lt;host_sentinel1&gt;:&lt;port_sentinel1&gt;,&lt;host_sentinel2&gt;:&lt;port_sentinel2&gt;,&lt;host_sentinel3&gt;:&lt;port_sentinel3&gt;
#   host: redis:6379
#   password: 
#   # Redis AUTH command was extended in Redis 6, it is possible to use it in the two-arguments AUTH &lt;username&gt; &lt;password&gt; form.
#   # there's a known issue when using external redis username ref:https://github.com/goharbor/harbor/issues/18892
#   # if you care about the image pull/push performance, please refer to this https://github.com/goharbor/harbor/wiki/Harbor-FAQs#external-redis-username-password-usage
#   # username:
#   # sentinel_master_set must be set to support redis+sentinel
#   #sentinel_master_set:
#   # db_index 0 is for core, it's unchangeable
#   registry_db_index: 1
#   jobservice_db_index: 2
#   trivy_db_index: 5
#   idle_timeout_seconds: 30
#   # it's optional, the db for harbor business misc, by default is 0, uncomment it if you want to change it.
#   # harbor_db_index: 6
#   # it's optional, the db for harbor cache layer, by default is 0, uncomment it if you want to change it.
#   # cache_layer_db_index: 7

# Uncomment uaa for trusting the certificate of uaa instance that is hosted via self-signed cert.
# uaa:
#   ca_file: /path/to/ca

# Global proxy
# Config http proxy for components, e.g. http://my.proxy.com:3128
# Components doesn't need to connect to each others via http proxy.
# Remove component from `components` array if want disable proxy
# for it. If you want use proxy for replication, MUST enable proxy
# for core and jobservice, and set `http_proxy` and `https_proxy`.
# Add domain to the `no_proxy` field, when you want disable proxy
# for some special registry.
proxy:
  http_proxy:
  https_proxy:
  no_proxy:
  components:
    - core
    - jobservice
    - trivy

# metric:
#   enabled: false
#   port: 9090
#   path: /metrics

# Trace related config
# only can enable one trace provider(jaeger or otel) at the same time,
# and when using jaeger as provider, can only enable it with agent mode or collector mode.
# if using jaeger collector mode, uncomment endpoint and uncomment username, password if needed
# if using jaeger agetn mode uncomment agent_host and agent_port
# trace:
#   enabled: true
#   # set sample_rate to 1 if you wanna sampling 100% of trace data; set 0.5 if you wanna sampling 50% of trace data, and so forth
#   sample_rate: 1
#   # # namespace used to differenciate different harbor services
#   # namespace:
#   # # attributes is a key value dict contains user defined attributes used to initialize trace provider
#   # attributes:
#   #   application: harbor
#   # # jaeger should be 1.26 or newer.
#   # jaeger:
#   #   endpoint: http://hostname:14268/api/traces
#   #   username:
#   #   password:
#   #   agent_host: hostname
#   #   # export trace data by jaeger.thrift in compact mode
#   #   agent_port: 6831
#   # otel:
#   #   endpoint: hostname:4318
#   #   url_path: /v1/traces
#   #   compression: false
#   #   insecure: true
#   #   # timeout is in seconds
#   #   timeout: 10

# Enable purge _upload directories
upload_purging:
  enabled: true
  # remove files in _upload directories which exist for a period of time, default is one week.
  age: 168h
  # the interval of the purge operations
  interval: 24h
  dryrun: false

# Cache layer configurations
# If this feature enabled, harbor will cache the resource
# `project/project_metadata/repository/artifact/manifest` in the redis
# which can especially help to improve the performance of high concurrent
# manifest pulling.
# NOTICE
# If you are deploying Harbor in HA mode, make sure that all the harbor
# instances have the same behaviour, all with caching enabled or disabled,
# otherwise it can lead to potential data inconsistency.
cache:
  # not enabled by default
  enabled: false
  # keep cache for one day by default
  expire_hours: 24

# Harbor core configurations
# Uncomment to enable the following harbor core related configuration items.
# core:
#   # The provider for updating project quota(usage), there are 2 options, redis or db,
#   # by default is implemented by db but you can switch the updation via redis which
#   # can improve the performance of high concurrent pushing to the same project,
#   # and reduce the database connections spike and occupies.
#   # By redis will bring up some delay for quota usage updation for display, so only
#   # suggest switch provider to redis if you were ran into the db connections spike aroud
#   # the scenario of high concurrent pushing to same project, no improvment for other scenes.
#   quota_update_provider: redis # Or db

</code></pre>
<hr>
<h2 id="é‡åˆ°çš„é—®é¢˜">é‡åˆ°çš„é—®é¢˜</h2>
<ol>
<li>æƒé™é—®é¢˜ï¼ˆcould not change group /var/run/docker.sock to docker: group docker not foundï¼‰ï¼Œè¯·ç”¨ root æƒé™æ‰§è¡Œ docker-compose up -d</li>
</ol>
<pre><code class="language-log">[+] Running 1/0
 âœ” Container harbor  Created                                                                                                 0.0s
Attaching to harbor
harbor  | Certificate request self-signature ok
harbor  | subject=CN = docker:dind server
harbor  | /certs/server/cert.pem: OK
harbor  | Certificate request self-signature ok
harbor  | subject=CN = docker:dind client
harbor  | /certs/client/cert.pem: OK
harbor  | [WARN  tini (12)] Tini is not running as PID 1 and isn't registered as a child subreaper.
harbor  | Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
harbor  | To fix the problem, use the -s option or set the environment variable TINI_SUBREAPER to register Tini as a child subreaper, or run Tini as PID 1.
harbor  | time=&quot;2023-08-30T10:38:50.129710991Z&quot; level=info msg=&quot;Starting up&quot;
harbor  | time=&quot;2023-08-30T10:38:50.131978924Z&quot; level=warning msg=&quot;could not change group /var/run/docker.sock to docker: group docker not found&quot;
harbor  | time=&quot;2023-08-30T10:38:50.132116243Z&quot; level=info msg=&quot;containerd not running, starting managed containerd&quot;
harbor  | failed to start containerd: libcontainerd: failed to save daemon pid to disk: process with PID 57 is still running
harbor  | Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?
harbor exited with code 1
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Jenkins - CI/CDï¼ˆæŒç»­é›†æˆã€æŒç»­äº¤ä»˜å’ŒæŒç»­éƒ¨ç½²ï¼‰]]></title>
        <id>https://cainiao1992.github.io/post/jenkins/</id>
        <link href="https://cainiao1992.github.io/post/jenkins/">
        </link>
        <updated>2023-08-29T10:13:40.000Z</updated>
        <content type="html"><![CDATA[<h2 id="docker-compose-å®‰è£…éƒ¨ç½²">docker-compose å®‰è£…éƒ¨ç½²</h2>
<pre><code class="language-bash">mkdir jenkins_home
chown -R 1000:1000 ./jenkins_home
</code></pre>
<ul>
<li>docker-compose.yml</li>
</ul>
<pre><code class="language-yaml">version: &quot;3&quot;

services:
  caddy:
    container_name: caddy
    image: caddy:alpine
    restart: unless-stopped
    ports:
      - &quot;80:80&quot;
      - &quot;80:80/udp&quot;
      - &quot;443:443&quot;
      - &quot;443:443/udp&quot;
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile
  jenkins:
    container_name: jenkins
    image: jenkins/jenkins:lts-jdk11
    restart: unless-stopped
    volumes:
      # chown -R 1000:1000 ./jenkins_home
      - ./jenkins_home:/var/jenkins_home
</code></pre>
<ul>
<li>Caddyfile</li>
</ul>
<pre><code class="language-Caddyfile">jenkins.uing.vip {
  log {
    output stdout
    format console
    level  ERROR
  }
  reverse_proxy jenkins:8080
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Portainer - å®¹å™¨è¿è¡Œç›‘æ§ç®¡ç†]]></title>
        <id>https://cainiao1992.github.io/post/portainer/</id>
        <link href="https://cainiao1992.github.io/post/portainer/">
        </link>
        <updated>2023-08-29T01:55:00.000Z</updated>
        <content type="html"><![CDATA[<h2 id="docker-compose-å®‰è£…éƒ¨ç½²">docker-compose å®‰è£…éƒ¨ç½²</h2>
<ul>
<li>docker-compose.yml</li>
</ul>
<pre><code class="language-yaml">version: &quot;3&quot;

services:
  caddy:
    container_name: caddy
    image: caddy:alpine
    restart: unless-stopped
    ports:
      - &quot;80:80&quot;
      - &quot;80:80/udp&quot;
      - &quot;443:443&quot;
      - &quot;443:443/udp&quot;
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile
  portainer:
    container_name: portainer
    image: portainer/portainer-ce:latest
    command: -H unix:///var/run/docker.sock
    restart: unless-stopped
    # ports:
    #   - 8000:8000
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./portainer:/data

  redis:
    container_name: redis
    image: redis:alpine
    restart: unless-stopped
    volumes:
      - ./redis:/data
</code></pre>
<ul>
<li>Caddyfile</li>
</ul>
<pre><code class="language-Caddyfile">portainer.uing.vip {
  log {
    output stdout
    format console
    level  ERROR
  }
  reverse_proxy portainer:9000
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Gitea - ä»£ç é¡¹ç›®ç®¡ç†]]></title>
        <id>https://cainiao1992.github.io/post/gitea/</id>
        <link href="https://cainiao1992.github.io/post/gitea/">
        </link>
        <updated>2023-08-26T21:00:45.000Z</updated>
        <content type="html"><![CDATA[<h1 id="gitea-å®‰è£…éƒ¨ç½²">Gitea å®‰è£…éƒ¨ç½²</h1>
<h2 id="é…ç½®-ssh-ç›´é€šå¯é€‰ä¸éœ€è¦-ssh-åè®®åŒæ­¥æ— éœ€æ­¤æ­¥éª¤å¯ä»¥ä½¿ç”¨-httpshttp-åè®®åŒæ­¥ä»£æ›¿">é…ç½® SSH ç›´é€šï¼ˆå¯é€‰ï¼Œä¸éœ€è¦ SSH åè®®åŒæ­¥æ— éœ€æ­¤æ­¥éª¤ï¼Œå¯ä»¥ä½¿ç”¨ https/http åè®®åŒæ­¥ä»£æ›¿ï¼‰</h2>
<pre><code class="language-bash"># è®°å½•ä¸‹ UID/GID æ›¿æ¢ä¸­çš„ USER_UID USER_GID
sudo adduser --system --shell /bin/bash --gecos 'Git Version Control' --group --disabled-password --home /home/git git
# ç”Ÿæˆ SSH å¯†é’¥å¯¹
sudo -u git ssh-keygen -t rsa -b 4096 -C &quot;Gitea Host Key&quot;

# ----------------------------------------------------------------

sudo -u git cat /home/git/.ssh/id_rsa.pub | sudo -u git tee -a /home/git/.ssh/authorized_keys
sudo -u git chmod 600 /home/git/.ssh/authorized_keys

cat &lt;&lt;&quot;EOF&quot; | sudo tee /usr/local/bin/gitea
#!/bin/sh
ssh -p 2222 -o StrictHostKeyChecking=no git@127.0.0.1 &quot;SSH_ORIGINAL_COMMAND=\&quot;$SSH_ORIGINAL_COMMAND\&quot; $0 $@&quot;
EOF
sudo chmod +x /usr/local/bin/gitea
</code></pre>
<h2 id="docker-compose-å®‰è£…éƒ¨ç½²">docker-compose å®‰è£…éƒ¨ç½²</h2>
<ul>
<li>docker-compose.yml</li>
</ul>
<pre><code class="language-yaml">version: &quot;3&quot;

services:
  caddy:
    container_name: caddy
    image: caddy:alpine
    restart: unless-stopped
    ports:
      - &quot;80:80&quot;
      - &quot;80:80/udp&quot;
      - &quot;443:443&quot;
      - &quot;443:443/udp&quot;
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile
  gitea:
    container_name: gitea
    image: gitea/gitea:latest
    restart: unless-stopped
    # depends_on:
    #   - redis
    environment:
      - USER=git
      - USER_UID=111
      - USER_GID=122
    volumes:
      - ./gitea:/data
      - /home/git/.ssh:/data/git/.ssh
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    ports:
      - &quot;127.0.0.1:2222:22&quot;


  # redis:
  #   container_name: redis
  #   image: redis:alpine
  #   restart: unless-stopped
  #   volumes:
  #     - ./redis:/data
</code></pre>
<ul>
<li>Caddyfile</li>
</ul>
<pre><code class="language-Caddyfile">:80 {
  redir https://{host}{uri}
}
gitea.uing.vip {
  log {
    output stdout
    format console
    level  ERROR
  }
  reverse_proxy gitea:3000
}
</code></pre>
<h2 id="å¯ç”¨-gitea-actions-å†…ç½®çš„-cicd-æŒç»­é›†æˆ-æŒç»­äº¤ä»˜å’ŒæŒç»­éƒ¨ç½²è§£å†³æ–¹æ¡ˆ">å¯ç”¨ Gitea Actions å†…ç½®çš„ CI/CD ï¼ˆæŒç»­é›†æˆã€æŒç»­äº¤ä»˜å’ŒæŒç»­éƒ¨ç½²ï¼‰è§£å†³æ–¹æ¡ˆ</h2>
<h3 id="é…ç½®-gitea-æœåŠ¡å™¨">é…ç½® Gitea æœåŠ¡å™¨</h3>
<pre><code class="language-bash">cat &lt;&lt; EOF &gt;&gt; gitea/gitea/conf/app.ini
[actions]
ENABLED=true
EOF
docker-compose restart gitea
</code></pre>
<h3 id="ç”Ÿæˆ-gitea-runner-é…ç½®æ–‡ä»¶">ç”Ÿæˆ  Gitea Runner é…ç½®æ–‡ä»¶</h3>
<pre><code>mkdir gitea_runner &amp;&amp; cd gitea_runner
docker run --entrypoint=&quot;&quot; --rm -it gitea/act_runner:latest act_runner generate-config &gt; config.yaml
</code></pre>
<h3 id="docker-compose-å®‰è£…-gitea-runner-éƒ¨ç½²">docker-compose å®‰è£… Gitea Runner éƒ¨ç½²</h3>
<ul>
<li>docker-compose.yml</li>
</ul>
<pre><code class="language-yaml">version: &quot;3&quot;

services:
  gitea_runner:
    container_name: gitea_runner
    image: gitea/act_runner:latest
    # å¦‚æœä½¿ç”¨æœåŠ¡å™¨å®¹å™¨åç§°ä½œä¸º URL HOST çš„è¯ï¼Œéœ€è¦å…ˆå¯åŠ¨ Gitea
    depends_on:
      - gitea
    environment:
      CONFIG_FILE: /config.yaml
      # Gitea æœåŠ¡å™¨åœ°å€ï¼ˆä¹Ÿå¯ä»¥æ˜¯å†…ç½‘åœ°å€æˆ–è€…å®¹å™¨å†…éƒ¨åœ°å€ï¼‰
      GITEA_INSTANCE_URL: https://gitea.uing.vip
      # è·å–åœ°å€ https://gitea.uing.vip/admin/actions/runners/
      GITEA_RUNNER_REGISTRATION_TOKEN: &quot;&quot;
      # Runneråç§°ï¼ˆå¯é€‰ï¼‰ã€‚å¦‚æœç•™ç©ºï¼Œå°†ä½¿ç”¨ä¸»æœºå
      GITEA_RUNNER_NAME: &quot;&quot;
      GITEA_RUNNER_LABELS: &quot;&quot;
    volumes:
      - ./gitea_runner/config.yaml:/config.yaml
      - ./gitea_runner/data:/data
      - /var/run/docker.sock:/var/run/docker.sock
</code></pre>
<h2 id="é…ç½®ä»“åº“å¯ç”¨-gitea-actions">é…ç½®ä»“åº“å¯ç”¨ Gitea Actions</h2>
<ol>
<li>æ‰“å¼€ä»“åº“è®¾ç½® https://gitea.uing.vip/&lt;owner&gt;/&lt;repo&gt;/settings</li>
<li>æ‰¾åˆ°å¹¶å‹¾é€‰ <strong>å¯ç”¨ Actions</strong> ï¼Œå¹¶ <strong>æ›´æ–°ä»“åº“è®¾ç½®</strong> ä¿å­˜è®¾ç½®<br>
<img src="https://cainiao1992.github.io/post-images/1693367900388.png" alt="enable_actions" loading="lazy"></li>
<li>åœ¨ä»“åº“ä»£ç ä¸‹æ–°å»ºç›®å½• <strong>.gitea/workflows/</strong>ï¼Œæ–°å»º Yaml æ–‡ä»¶ç¼–å†™ Gitea Actions æ‰§è¡Œä»£ç </li>
</ol>
<pre><code class="language-bash">git clone git@gitea.uing.vip:cainiao/gitea_runner.git

cd gitea_runner &amp;&amp; mkdir -p .gitea/workflows/

cat &lt;&lt;&quot;EOF&quot; &gt; .gitea/workflows/demo.yaml
name: Gitea Actions Demo
run-name: ${{ gitea.actor }} is testing out Gitea Actions ğŸš€
on: [push]

jobs:
  Explore-Gitea-Actions:
    runs-on: ubuntu-latest
    steps:
      - run: echo &quot;ğŸ‰ The job was automatically triggered by a ${{ gitea.event_name }} event.&quot;
      - run: echo &quot;ğŸ§ This job is now running on a ${{ runner.os }} server hosted by Gitea!&quot;
      - run: echo &quot;ğŸ” The name of your branch is ${{ gitea.ref }} and your repository is ${{ gitea.repository }}.&quot;
      - name: Check out repository code
        uses: actions/checkout@v3
      - run: echo &quot;ğŸ’¡ The ${{ gitea.repository }} repository has been cloned to the runner.&quot;
      - run: echo &quot;ğŸ–¥ï¸ The workflow is now ready to test your code on the runner.&quot;
      - name: List files in the repository
        run: |
          ls ${{ gitea.workspace }}
      - run: echo &quot;ğŸ This job's status is ${{ job.status }}.&quot;
EOF

git add .gitea/workflows/demo.yaml
git commit -m &quot;add .gitea/workflows/demo.yaml&quot;
git push
</code></pre>
<ol start="4">
<li>åœ¨ä»“åº“çš„ Actions ä¸‹æŸ¥çœ‹åˆ°æ‰§è¡Œè¿‡ç¨‹åŠç»“æœï¼šhttps://gitea.uing.vip/&lt;owner&gt;/&lt;repo&gt;/actions</li>
</ol>
<h2 id="ç›¸å…³è¿æ¥">ç›¸å…³è¿æ¥</h2>
<ul>
<li>(Configuration Cheat Sheet)[https://docs.gitea.com/administration/config-cheat-sheet]</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Git ä½¿ç”¨ç¬”è®°]]></title>
        <id>https://cainiao1992.github.io/post/git/</id>
        <link href="https://cainiao1992.github.io/post/git/">
        </link>
        <updated>2023-08-17T08:59:29.000Z</updated>
        <content type="html"><![CDATA[<h1 id="git-ä½¿ç”¨ç¬”è®°">Git ä½¿ç”¨ç¬”è®°</h1>
<h2 id="ä»ä¸»ä»“åº“æ›´æ–°ä»£ç åˆ°-fork-ä»“åº“">ä»ä¸»ä»“åº“æ›´æ–°ä»£ç åˆ° fork ä»“åº“</h2>
<pre><code class="language-shell">git remote -v
git remote add github https://github.com/chenxiangfang/Main.git
git fetch github
git merge github/master
git push
</code></pre>
<h2 id="ä»-github-ä¸­æ‹‰å–å˜æ›´åŒæ­¥åˆ°æœ¬åœ°å¹¶æäº¤åˆ°-fork-ä»“åº“">ä» github ä¸­æ‹‰å–å˜æ›´åŒæ­¥åˆ°æœ¬åœ°ï¼Œå¹¶æäº¤åˆ° fork ä»“åº“</h2>
<pre><code class="language-shell">git fetch github
git merge github/master
git push
git fetch github --all
git push origin --all
</code></pre>
<h2 id="é…ç½®-git-æäº¤æ—¶çš„é‚®ç®±å’Œç”¨æˆ·å">é…ç½® Git æäº¤æ—¶çš„é‚®ç®±å’Œç”¨æˆ·å</h2>
<pre><code class="language-shell"># å…¨å±€ä¿®æ”¹
git config --global user.email &quot;565499699@qq.com&quot;
git config --global user.name &quot;Xiangfang Chen&quot;
# å½“å‰ä»“åº“ä¿®æ”¹
git config user.email &quot;565499699@qq.com&quot;
git config user.name &quot;Xiangfang Chen&quot;
</code></pre>
<h2 id="è®¾ç½®-httphttps-å…å¯†ç™»å½•git-clone-ç¬¬äºŒæ¬¡ä¸éœ€è¦å†æ¬¡è¾“å…¥å¯†ç äº†">è®¾ç½® HTTP/HTTPS å…å¯†ç™»å½•ï¼ˆgit clone ç¬¬äºŒæ¬¡ä¸éœ€è¦å†æ¬¡è¾“å…¥å¯†ç äº†ï¼‰</h2>
<pre><code class="language-bash">git config --global credential.helper store
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[CentOS]]></title>
        <id>https://cainiao1992.github.io/post/centos/</id>
        <link href="https://cainiao1992.github.io/post/centos/">
        </link>
        <updated>2023-08-17T08:54:11.000Z</updated>
        <content type="html"><![CDATA[<h2 id="centos-7-ç½‘ç»œé…ç½®">CentOS 7 ç½‘ç»œé…ç½®</h2>
<pre><code class="language-shell"># ç½‘ç»œé…ç½®
sed -i 's/ONBOOT=&quot;no&quot;/ONBOOT=&quot;yes&quot;/g' /etc/sysconfig/network-scripts/ifcfg-eth0
sed -i 's/IPV6INIT=&quot;yes&quot;/IPV6INIT=&quot;no&quot;/g' /etc/sysconfig/network-scripts/ifcfg-eth0
sed -i 's/BOOTPROTO=&quot;dhcp&quot;/BOOTPROTO=&quot;none&quot;/g' /etc/sysconfig/network-scripts/ifcfg-eth0

sed -i 's/ONBOOT=no/ONBOOT=yes/g' /etc/sysconfig/network-scripts/ifcfg-eth0
sed -i 's/IPV6INIT=yes/IPV6INIT=no/g' /etc/sysconfig/network-scripts/ifcfg-eth0
sed -i 's/BOOTPROTO=dhcp/BOOTPROTO=none/g' /etc/sysconfig/network-scripts/ifcfg-eth0

cat &lt;&lt; EOF &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-eth0
IPADDR=192.168.2.23
PREFIX=16
GATEWAY=192.168.1.1
DNS1=114.114.114.114
DNS2=192.168.1.1
EOF
cat &lt;&lt; EOF &gt;/etc/hostname
QRadarCE
EOF
</code></pre>
<h2 id="centos-7-å®‰è£…å¿…å¤‡åŒ…">CentOS 7 å®‰è£…å¿…å¤‡åŒ…</h2>
<pre><code class="language-shell"># å¿…å¤‡è½¯ä»¶
yum install -y epel-release
yum update -y
yum install -y bash-completion bash-completion-extras sudo openssh-server
systemctl enable sshd
systemctl start sshd
ln -s -f /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
reboot
</code></pre>
<h2 id="centos-6-å®‰è£…å¿…å¤‡åŒ…">CentOS 6 å®‰è£…å¿…å¤‡åŒ…</h2>
<pre><code class="language-shell">mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup
curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-vault-6.10.repo
yum clean all &amp;&amp; yum makecache
yum install -y epel-release
yum update -y
yum install -y bash-completion bash-completion-extras sudo openssh-server
echo &quot;PermitRootLogin yes&quot; | tee /etc/ssh/sshd_config

ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key
ssh-keygen -t dsa -f /etc/ssh/ssh_host_dsa_key
ssh-keygen -t ecdsa -f /etc/ssh/ssh_host_ecdsa_key
ssh-keygen -t ed25519 -f /etc/ssh/ssh_host_ed25519_key

chkconfig sshdÂ on
service sshd start
ln -s -f /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
</code></pre>
<h2 id="extra-packages-for-enterprise-linux-epel">Extra Packages for Enterprise Linux (EPEL)</h2>
<pre><code class="language-shell">yum install -y epel-release
</code></pre>
<h2 id="elrepo-project">ELRepo Project</h2>
<p>Import the public key:</p>
<pre><code class="language-shell">rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org
</code></pre>
<p>To install ELRepo for RHEL-9:</p>
<pre><code class="language-bash">yum installÂ https://www.elrepo.org/elrepo-release-9.el9.elrepo.noarch.rpm
</code></pre>
<p>To install ELRepo for RHEL-8:</p>
<pre><code class="language-shell">yum install https://www.elrepo.org/elrepo-release-8.el8.elrepo.noarch.rpm
</code></pre>
<p>To install ELRepo for RHEL-7, SL-7 or CentOS-7:</p>
<pre><code class="language-shell">yum install https://www.elrepo.org/elrepo-release-7.el7.elrepo.noarch.rpm
</code></pre>
<p>å®‰è£…é•¿æœŸæ”¯æŒå†…æ ¸ï¼ˆlt = long timeï¼‰</p>
<pre><code class="language-shell">yum --enablerepo=elrepo-kernel -y install kernel-lt
</code></pre>
<p>å®‰è£…ç¨³å®šä¸»çº¿å†…æ ¸kernel-mlï¼ˆml=mainlineï¼‰</p>
<pre><code class="language-shell">yum --enablerepo=elrepo-kernel -y install kernel-ml
</code></pre>
<h3 id="çº¢å¸½è½¯ä»¶é›†åˆ">çº¢å¸½è½¯ä»¶é›†åˆ</h3>
<p>https://access.redhat.com/support/policy/updates/rhscl-rhel7</p>
<pre><code class="language-shell">yum install centos-release-scl â€“y
</code></pre>
<p>å®‰è£… GCC 9</p>
<pre><code class="language-shell">yum install devtoolset-9-toolchain â€“y
# ä¸´æ—¶ä½¿ç”¨
scl enable devtoolset-9 bash
source scl_source enable devtoolset-9

å®‰è£… GCC 7
```shell
yum install devtoolset-7-toolchain â€“y
# ä¸´æ—¶ä½¿ç”¨
scl enable devtoolset-7 bash
source scl_source enable devtoolset-7
</code></pre>
<p>å®‰è£… Python 3.8</p>
<pre><code class="language-shell">yum install rh-python38 rh-python38-python-devel â€“y
# ä¸´æ—¶ä½¿ç”¨
scl enable rh-python38 bash
source scl_source enable rh-python38
</code></pre>
<h2 id="mysql-server-57">MySQL Server 5.7</h2>
<pre><code class="language-shell">yum install -y http://repo.mysql.com/mysql57-community-release-el7.rpm
rpm -import http://repo.mysql.com/RPM-GPG-KEY-mysql-2022

yum install mysql-server -y

systemctl enable mysqld
systemctl start mysqld

grep 'temporary password'  /var/log/mysqld.log
</code></pre>
<h2 id="mysql-server-80">MySQL Server 8.0</h2>
<pre><code class="language-shell">yum install -y https://repo.mysql.com/mysql80-community-release-el7.rpm
rpm -import http://repo.mysql.com/RPM-GPG-KEY-mysql-2022

yum install mysql-server -y

systemctl enable mysqld
systemctl start mysqld

grep 'temporary password'  /var/log/mysqld.log
</code></pre>
<h2 id="nginx">Nginx</h2>
<pre><code class="language-shell">yum install -y https://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm
yum install -y nginx
systemctl enable nginx
systemctl start nginx
</code></pre>
<h2 id="redis-32">Redis 3.2</h2>
<pre><code class="language-shell">yum install -y redis
systemctl enable redis
systemctl start redis
</code></pre>
<h2 id="redis-6">Redis 6</h2>
<pre><code class="language-shell">yum install -y \
https://repo.ius.io/ius-release-el7.rpm \
https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm
yum install -y redis6
systemctl enable redis
systemctl start redis
</code></pre>
<h2 id="openjdk">OpenJDK</h2>
<pre><code class="language-shell"># openjdk 8
yum install -y java-1.8.0-openjdk java-1.8.0-openjdk-devel

# openjdk 11
yum install -y java-11-openjdk java-11-openjdk-devel
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[å¸è½½äº‘æœåŠ¡ç›‘æ§]]></title>
        <id>https://cainiao1992.github.io/post/uninstall-cloud-server-monitor/</id>
        <link href="https://cainiao1992.github.io/post/uninstall-cloud-server-monitor/">
        </link>
        <updated>2023-08-17T08:45:14.000Z</updated>
        <content type="html"><![CDATA[<h2 id="aliyun">AliYun</h2>
<pre><code class="language-bash"># å¸è½½äº‘ç›¾ï¼ˆå®‰éª‘å£«ï¼‰
curl http://update.aegis.aliyun.com/download/uninstall.sh | bash
curl http://update.aegis.aliyun.com/download/quartz_uninstall.sh | bash

sudo rm -r /usr/local/aegis
sudo systemctl disable aliyun.service
sudo rm /usr/sbin/aliyun-service
sudo rm /usr/sbin/aliyun-service.backup
sudo rm /usr/sbin/aliyun_installer
sudo rm /etc/systemd/system/aliyun.service
sudo rm /lib/systemd/system/aliyun.service

# å¸è½½äº‘åŠ©æ‰‹Agent
/usr/local/share/assist-daemon/assist_daemon --stop
/usr/local/share/assist-daemon/assist_daemon --delete
rm -rf /usr/local/share/assist-daemon

systemctl stop aliyun.service
apt remove  aliyun-assist -y
dpkg -l |grep &quot;^rc&quot;|awk '{print $2}'|sudo xargs apt -y purge
rm -rf /usr/local/share/aliyun-assist
</code></pre>
<blockquote>
<p>äº‘ç›‘æ§</p>
</blockquote>
<pre><code class="language-bash"># å¸è½½äº‘ç›‘æ§ Go è¯­è¨€ç‰ˆ
# åœæ­¢
/usr/local/cloudmonitor/CmsGoAgent.linux-* stop
# ä»ç³»ç»ŸæœåŠ¡ä¸­ç§»é™¤
/usr/local/cloudmonitor/CmsGoAgent.linux-* uninstall

# å¸è½½
/usr/local/cloudmonitor/CmsGoAgent.linux-* stop &amp;&amp; \
/usr/local/cloudmonitor/CmsGoAgent.linux-* uninstall &amp;&amp; \
rm -rf /usr/local/cloudmonitor

# å¸è½½äº‘ç›‘æ§ Java ç‰ˆ
# åœæ­¢
/usr/local/cloudmonitor/wrapper/bin/cloudmonitor.sh stop

# å¸è½½
/usr/local/cloudmonitor/wrapper/bin/cloudmonitor.sh remove &amp;&amp; \
rm -rf /usr/local/cloudmonitor
</code></pre>
<h2 id="qcloud">QCloud</h2>
<pre><code class="language-bash">/usr/local/qcloud/stargate/admin/stop.sh
/usr/local/qcloud/YunJing/stopYDCore.sh
/usr/local/qcloud/monitor/barad/admin/stop.sh

/usr/local/qcloud/stargate/admin/uninstall.sh
/usr/local/qcloud/YunJing/uninst.sh
/usr/local/qcloud/monitor/barad/admin/uninstall.sh
rm -rf /usr/local/qcloud
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[åˆå§‹åŒ– VPS]]></title>
        <id>https://cainiao1992.github.io/post/initialize-the-vps/</id>
        <link href="https://cainiao1992.github.io/post/initialize-the-vps/">
        </link>
        <updated>2023-08-17T08:21:02.000Z</updated>
        <content type="html"><![CDATA[<h1 id="ubuntu">Ubuntu</h1>
<h2 id="åŸºç¡€æ“ä½œ">åŸºç¡€æ“ä½œ</h2>
<h3 id="å®¢æˆ·ç«¯">å®¢æˆ·ç«¯</h3>
<pre><code class="language-bash"># é…ç½®å…å¯†ç™»å½•
ssh-copy-id root@uing.vip
</code></pre>
<h3 id="æœåŠ¡å™¨">æœåŠ¡å™¨</h3>
<pre><code class="language-bash">apt update &amp;&amp; apt -o Dpkg::Options::=&quot;--force-confnew&quot; full-upgrade -y &amp;&amp; apt autoremove -y
apt install -y curl htop vim ufw sudo bash-completion

cat &gt;&gt; /etc/security/limits.conf &lt;&lt; EOF
# End of file
*     soft   nofile    655360
*     hard   nofile    655360
*     soft   nproc     655360
*     hard   nproc     655360
*     soft   core      655360
*     hard   core      655360
*     hard   memlock   unlimited
*     soft   memlock   unlimited
EOF

cat &gt;&gt; /etc/sysctl.conf &lt;&lt; EOF
net.core.rmem_max=33554432
net.core.wmem_max=33554432
net.core.default_qdisc=fq
net.ipv4.tcp_congestion_control=bbr
EOF
sysctl -p

cat &gt; /etc/hostname &lt;&lt; EOF
uing.vip
EOF
cat &gt;&gt; /etc/hosts &lt;&lt; EOF
127.0.1.1 uing.vip
EOF

# è®¾ç½®ä¸Šæµ·æ—¶åŒº
ln -s -f /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
timedatectl set-timezone Asia/Shanghai

# é˜²ç«å¢™é…ç½®
ufw default deny
ufw allow ssh
ufw allow http
ufw allow https
ufw allow 443/udp
ufw enable

# é‡å¯
reboot

# Certbot HTTPS è¯ä¹¦å®‰è£…ç»­è®¢
apt install -y certbot
certbot certonly --standalone --agree-tos --register-unsafely-without-email -d uing.vip
</code></pre>
<h2 id="å®‰è£…-docker">å®‰è£… Docker</h2>
<pre><code class="language-bash">curl https://get.docker.com/ | sh
ln -s /usr/libexec/docker/cli-plugins/docker-compose /usr/local/bin/docker-compose
# æ›´æ–¹ä¾¿ä½¿ç”¨ docker exec å‘½ä»¤
sudo tee /usr/local/bin/dssh &gt; /dev/null &lt;&lt; EOF
#!/bin/sh
docker exec -it \$1 sh
EOF
sudo chmod a+x /usr/local/bin/dssh

# è®© Docker æ”¯æŒ IPv6
sudo tee /etc/docker/daemon.json &gt; /dev/null &lt;&lt; EOF
{
  &quot;ipv6&quot;: true,
  &quot;fixed-cidr-v6&quot;: &quot;2001:db8:1::/64&quot;,
  &quot;experimental&quot;: true,
  &quot;ip6tables&quot;: true
}
EOF
sudo systemctl restart docker

# åˆ›å»º Docker VPS å®¹å™¨ç½‘ç»œ
docker network create \
  --driver=bridge \
  --subnet=172.16.1.0/24 \
  --ip-range=172.16.1.0/24 \
  --gateway=172.16.1.1 \
  vps

# æ”¯æŒ IPv6
docker network create \
  --driver=bridge \
  --ipv6 \
  --subnet=172.16.1.0/24 \
  --ip-range=172.16.1.0/24 \
  --gateway=172.16.1.1 \
  --subnet=2001:0DB8::1:0/112 \
  --ip-range2001:0DB8::1:0/112 \
  --gateway=2001:db8::1:1 \
  vps
</code></pre>
]]></content>
    </entry>
</feed>