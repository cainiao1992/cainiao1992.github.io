<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://cainiao1992.github.io</id>
    <title>菜鸟的笔记</title>
    <updated>2023-11-25T04:05:23.698Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://cainiao1992.github.io"/>
    <link rel="self" href="https://cainiao1992.github.io/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://cainiao1992.github.io/images/avatar.png</logo>
    <icon>https://cainiao1992.github.io/favicon.ico</icon>
    <rights>All rights reserved 2023, 菜鸟的笔记</rights>
    <entry>
        <title type="html"><![CDATA[OpenSSH 笔记]]></title>
        <id>https://cainiao1992.github.io/post/openssh/</id>
        <link href="https://cainiao1992.github.io/post/openssh/">
        </link>
        <updated>2023-09-01T08:31:23.000Z</updated>
        <content type="html"><![CDATA[<p>配置免密登录</p>
<pre><code class="language-shell"># 创建SSH密钥对。
ssh-keygen -t rsa -b 4096

# 获取SSH公钥。
cat ~/.ssh/id_rsa.pub

# 配置免密登录的服务器主机。
ssh-copy-id root@uing.vip
``

配置 root 用户登录
``` shell
vi /etc/ssh/sshd_config
# root 用户登录
# prohibit-password / without-password:禁止密码登录 root
# yes: 允许使用密码登录 root
# no: 禁止登录 root
# PermitRootLogin yes
# 能否使用密码登录SSH (包括其它用户)
# PasswordAuthentication no

echo &quot;PermitRootLogin yes&quot; | sudo tee /etc/ssh/sshd_config
systemctl restart sshd
</code></pre>
<p>解除（清除）信任主机公钥</p>
<pre><code class="language-shell">ssh-keygen -R uing.vip
</code></pre>
<h1 id="ssh-跳板机连接方法">SSH 跳板机连接方法</h1>
<pre><code class="language-bash">ssh username@目标机器IP -p 22 -J username@跳板机IP:22
</code></pre>
<p>产生64bit随机数</p>
<pre><code class="language-bash">openssl rand -base64 64
</code></pre>
<hr>
<h3 id="遇到的问题">遇到的问题</h3>
<p>使用过时的密钥算法</p>
<pre><code>Unable to negotiate with 192.168.2.21 port 22: no matching host key type found. Their offer: ssh-rsa,ssh-dss
</code></pre>
<p>解决</p>
<pre><code class="language-shell"># 增加 -oHostKeyAlgorithms=+ssh-dss 选项
ssh -oHostKeyAlgorithms=+ssh-dss root@192.168.2.21
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Caddy2 - 能够自动申请证书的 HTTPS/HTTP 服务器]]></title>
        <id>https://cainiao1992.github.io/post/caddy2/</id>
        <link href="https://cainiao1992.github.io/post/caddy2/">
        </link>
        <updated>2023-08-29T13:54:39.000Z</updated>
        <content type="html"><![CDATA[<h2 id="自动https">自动HTTPS</h2>
<p>当符合下面一些合理的标准时，Caddy会自动为所有站点启用HTTPS:</p>
<ul>
<li>主机名
<ul>
<li>不为空</li>
<li>不是localhost</li>
<li>不是一个IP地址</li>
<li>不超过一个通配符（*）</li>
<li>通配符必须是最左边的标签</li>
</ul>
</li>
<li>没有显式指定端口为80</li>
<li>没有显式指定使用http协议</li>
<li>TLS没有在站点的定义中被关闭</li>
<li>不是你自己提供的证书和密钥</li>
<li>Caddy能够绑定到端口80和443（除非使用DNS验证）</li>
</ul>
<p>Caddy还会将所有HTTP请求重定向到与HTTPS对应的地址，只要Caddyfile中没有定义主机名的纯文本变体。</p>
<hr>
<h2 id="安装部署">安装部署</h2>
<ul>
<li>docker-compose.yml</li>
</ul>
<pre><code class="language-yaml">version: &quot;3&quot;

services:
  caddy:
    container_name: caddy
    image: caddy:alpine
    restart: unless-stopped
    ports:
      - &quot;80:80&quot;
      - &quot;80:80/udp&quot;
      - &quot;443:443&quot;
      - &quot;443:443/udp&quot;
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile
      - ./caddy/:/data/caddy/
</code></pre>
<ul>
<li>Caddyfile</li>
</ul>
<pre><code class="language-Caddyfile">:80 {
  redir https://{host}{uri}
}

uing.vip {
  log {
    output stdout
    format console
    level  ERROR
  }
  root * /var/www/uing.vip
  handle_errors {
    rewrite * /404.html
    file_server
  }
  file_server
}

gitea.uing.vip {
  log {
    output stdout
    format console
    level  ERROR
  }
  reverse_proxy gitea:3000
}
</code></pre>
<h2 id="如果需要接入-cloudflare-cdn-上">如果需要接入 Cloudflare CDN 上</h2>
<ol>
<li>打开 https://dash.cloudflare.com/ 注册登录</li>
<li>添加网站，更改域名的 DNS</li>
<li>打开 https://dash.cloudflare.com/profile/api-tokens</li>
<li>API 令牌 -&gt; 创建 API 令牌 -&gt; 编辑区域 DNS -&gt; 选择模板 -&gt; 区域资源 -&gt; 对应网站</li>
<li>获取到的API KEY -&gt; docker-compose.yml -&gt; caddy 容器 -&gt; 替换 CF_API_TOKEN 环境变量 -&gt; 替换 DOMAIN 环境变量（也可以是二级或三级域名）</li>
<li>https://dash.cloudflare.com -&gt; 对应网站</li>
<li>SSL/TLS -&gt; 源服务器 -&gt; 源证书 -&gt;  经过身份验证的源服务器拉取 -&gt; 打开</li>
<li>SSL/TLS -&gt; 概述 -&gt; 您的 SSL/TLS 加密模式为 -&gt; 完全（严格）</li>
</ol>
<ul>
<li>docker-compose.yml</li>
</ul>
<pre><code class="language-yaml">version: &quot;3&quot;
services:
  caddy:
    container_name: caddy
    build: 
      dockerfile: ./caddy-cloudflare-Dockerfile
    restart: unless-stopped
    depends_on:
      - sing-box
      # - subconverter
    ports:
      - &quot;80:80&quot;
      - &quot;80:80/udp&quot;
      - &quot;443:443&quot;
      - &quot;443:443/udp&quot;
    environment:
      - CF_API_TOKEN=XXX
      - DOMAIN=XXX
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile
      - ./caddy:/data/caddy
</code></pre>
<ul>
<li>Caddyfile</li>
</ul>
<pre><code class="language-Caddyfile">{env.DOMAIN} {
  log {
    output stdout
    format console
    level  ERROR
  }
  reverse_proxy gitea:3000
}
</code></pre>
<ul>
<li>caddy-cloudflare-Dockerfile</li>
</ul>
<pre><code class="language-Dockerfile">FROM caddy:builder-alpine AS builder
RUN xcaddy build --with github.com/caddy-dns/cloudflare

FROM caddy:alpine
COPY --from=builder /usr/bin/caddy /usr/bin/caddy
</code></pre>
<h2 id="相关连接">相关连接</h2>
<ul>
<li><a href="https://caddyserver.com/docs">Caddy Docs</a></li>
<li><a href="https://caddy2.dengxiaolong.com/docs/">Caddy v2中文文档</a></li>
<li><a href="https://dengxiaolong.com/caddy/zh/">Caddy中文文档(V1)</a></li>
<li><a href="https://github.com/caddy-dns/cloudflare">Cloudflare module for Caddy</a></li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Harbor - 私有化容器仓库]]></title>
        <id>https://cainiao1992.github.io/post/harbor/</id>
        <link href="https://cainiao1992.github.io/post/harbor/">
        </link>
        <updated>2023-08-29T11:26:12.000Z</updated>
        <content type="html"><![CDATA[<ul>
<li>docker-compose.yml</li>
</ul>
<pre><code class="language-yaml">version: &quot;3&quot;

services:
  caddy:
    container_name: caddy
    image: caddy:alpine
    restart: unless-stopped
    ports:
      - &quot;80:80&quot;
      - &quot;80:80/udp&quot;
      - &quot;443:443&quot;
      - &quot;443:443/udp&quot;
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile
  harbor:
    container_name: harbor
    build:
      dockerfile: ./harbor-Dockerfile
    privileged: true
    volumes:
      - ./harbor/data:/data
      - ./harbor/harbor:/opt/harbor
</code></pre>
<ul>
<li>Caddyfile</li>
</ul>
<pre><code class="language-Caddyfile">registry.uing.vip {
  log {
    output stdout
    format console
    level  ERROR
  }
  reverse_proxy harbor:9000
}
</code></pre>
<ul>
<li>harbor-Dockerfile</li>
</ul>
<pre><code class="language-Dockerfile">FROM docker:dind
MAINTAINER cainiao &lt;565499699@qq.com&gt;

COPY harbor/harbor-entrypoint.sh /usr/local/bin/harbor-entrypoint.sh
COPY harbor/supervisord.conf /etc/supervisord.conf
COPY harbor/harbor.yml /harbor.yml

RUN apk add --no-cache supervisor &amp;&amp; chmod a+x /usr/local/bin/harbor-entrypoint.sh

ENTRYPOINT [&quot;/usr/bin/supervisord&quot;, &quot;-c&quot;, &quot;/etc/supervisord.conf&quot;]
</code></pre>
<ul>
<li>harbor/harbor-entrypoint.sh</li>
</ul>
<pre><code class="language-bash">#!/bin/sh

if [ -f /opt/harbor/docker-compose.yml ]; then
    cd /opt/harbor/ &amp;&amp; docker-compose up
else
    cd /opt
    apk add --no-cache --virtual .build_tools ncurses bash wget
    
    wget -O harbor-online-installer.tgz \
        https://github.com/goharbor/harbor/releases/download/v2.8.4/harbor-online-installer-v2.8.4.tgz \
        &amp;&amp; tar xzf harbor-online-installer.tgz \
        &amp;&amp; rm -f harbor-online-installer.tgz
    
    cd /opt/harbor
    
    cp -f /harbor.yml .
    bash ./install.sh

    apk del .build_tools
    
    docker-compose logs -f
fi
</code></pre>
<ul>
<li>harbor/supervisord.conf</li>
</ul>
<pre><code class="language-ini">[supervisord]
nodaemon=true

[program:dockerd]
command=/usr/local/bin/dockerd-entrypoint.sh
stdout_logfile=/dev/stdout
stdout_logfile_maxbytes=0
stderr_logfile=/dev/stderr
stderr_logfile_maxbytes=0
autostar=true
autorestart=true

[program:harbor]
command=/usr/local/bin/harbor-entrypoint.sh
stdout_logfile=/dev/stdout
stdout_logfile_maxbytes=0
stderr_logfile=/dev/stderr
stderr_logfile_maxbytes=0
autostar=true
autorestart=true
startsecs=3
</code></pre>
<ul>
<li>harbor/harbor.yml</li>
</ul>
<pre><code class="language-yaml"># Configuration file of Harbor

# The IP address or hostname to access admin UI and registry service.
# DO NOT use localhost or 127.0.0.1, because Harbor needs to be accessed by external clients.
hostname: registry.uing.vip

# http related config
http:
  # port for http, default is 80. If https enabled, this port will redirect to https port
  port: 80

# # https related config
# https:
#   # https port for harbor, default is 443
#   port: 443
#   # The path of cert and key files for nginx
#   certificate: /your/certificate/path
#   private_key: /your/private/key/path


# # Uncomment following will enable tls communication between all harbor components
# internal_tls:
#   # set enabled to true means internal tls is enabled
#   enabled: true
#   # put your cert and key files on dir
#   dir: /etc/harbor/tls/internal
#   # enable strong ssl ciphers (default: false)
#   strong_ssl_ciphers: false

# Uncomment external_url if you want to enable external proxy
# And when it enabled the hostname will no longer used
external_url: https://registry.uing.vip

# The initial password of Harbor admin
# It only works in first time to install harbor
# Remember Change the admin password from UI after launching Harbor.
harbor_admin_password: XXXXXXXXXXXX

# Harbor DB configuration
database:
  # The password for the root user of Harbor DB. Change this before any production use.
  password: root123
  # The maximum number of connections in the idle connection pool. If it &lt;=0, no idle connections are retained.
  max_idle_conns: 100
  # The maximum number of open connections to the database. If it &lt;= 0, then there is no limit on the number of open connections.
  # Note: the default number of connections is 1024 for postgres of harbor.
  max_open_conns: 900
  # The maximum amount of time a connection may be reused. Expired connections may be closed lazily before reuse. If it &lt;= 0, connections are not closed due to a connection's age.
  # The value is a duration string. A duration string is a possibly signed sequence of decimal numbers, each with optional fraction and a unit suffix, such as &quot;300ms&quot;, &quot;-1.5h&quot; or &quot;2h45m&quot;. Valid time units are &quot;ns&quot;, &quot;us&quot; (or &quot;µs&quot;), &quot;ms&quot;, &quot;s&quot;, &quot;m&quot;, &quot;h&quot;.
  conn_max_lifetime: 5m
  # The maximum amount of time a connection may be idle. Expired connections may be closed lazily before reuse. If it &lt;= 0, connections are not closed due to a connection's idle time.
  # The value is a duration string. A duration string is a possibly signed sequence of decimal numbers, each with optional fraction and a unit suffix, such as &quot;300ms&quot;, &quot;-1.5h&quot; or &quot;2h45m&quot;. Valid time units are &quot;ns&quot;, &quot;us&quot; (or &quot;µs&quot;), &quot;ms&quot;, &quot;s&quot;, &quot;m&quot;, &quot;h&quot;.
  conn_max_idle_time: 0

# The default data volume
data_volume: /data

# Harbor Storage settings by default is using /data dir on local filesystem
# Uncomment storage_service setting If you want to using external storage
# storage_service:
#   # ca_bundle is the path to the custom root ca certificate, which will be injected into the truststore
#   # of registry's containers.  This is usually needed when the user hosts a internal storage with self signed certificate.
#   ca_bundle:

#   # storage backend, default is filesystem, options include filesystem, azure, gcs, s3, swift and oss
#   # for more info about this configuration please refer https://docs.docker.com/registry/configuration/
#   filesystem:
#     maxthreads: 100
#   # set disable to true when you want to disable registry redirect
#   redirect:
#     disable: false

# Trivy configuration
#
# Trivy DB contains vulnerability information from NVD, Red Hat, and many other upstream vulnerability databases.
# It is downloaded by Trivy from the GitHub release page https://github.com/aquasecurity/trivy-db/releases and cached
# in the local file system. In addition, the database contains the update timestamp so Trivy can detect whether it
# should download a newer version from the Internet or use the cached one. Currently, the database is updated every
# 12 hours and published as a new release to GitHub.
trivy:
  # ignoreUnfixed The flag to display only fixed vulnerabilities
  ignore_unfixed: false
  # skipUpdate The flag to enable or disable Trivy DB downloads from GitHub
  #
  # You might want to enable this flag in test or CI/CD environments to avoid GitHub rate limiting issues.
  # If the flag is enabled you have to download the `trivy-offline.tar.gz` archive manually, extract `trivy.db` and
  # `metadata.json` files and mount them in the `/home/scanner/.cache/trivy/db` path.
  skip_update: false
  #
  # The offline_scan option prevents Trivy from sending API requests to identify dependencies.
  # Scanning JAR files and pom.xml may require Internet access for better detection, but this option tries to avoid it.
  # For example, the offline mode will not try to resolve transitive dependencies in pom.xml when the dependency doesn't
  # exist in the local repositories. It means a number of detected vulnerabilities might be fewer in offline mode.
  # It would work if all the dependencies are in local.
  # This option doesn't affect DB download. You need to specify &quot;skip-update&quot; as well as &quot;offline-scan&quot; in an air-gapped environment.
  offline_scan: false
  #
  # Comma-separated list of what security issues to detect. Possible values are `vuln`, `config` and `secret`. Defaults to `vuln`.
  security_check: vuln
  #
  # insecure The flag to skip verifying registry certificate
  insecure: false
  # github_token The GitHub access token to download Trivy DB
  #
  # Anonymous downloads from GitHub are subject to the limit of 60 requests per hour. Normally such rate limit is enough
  # for production operations. If, for any reason, it's not enough, you could increase the rate limit to 5000
  # requests per hour by specifying the GitHub access token. For more details on GitHub rate limiting please consult
  # https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting
  #
  # You can create a GitHub token by following the instructions in
  # https://help.github.com/en/github/authenticating-to-github/creating-a-personal-access-token-for-the-command-line
  #
  # github_token: xxx

jobservice:
  # Maximum number of job workers in job service
  max_job_workers: 10
  # The jobLoggers backend name, only support &quot;STD_OUTPUT&quot;, &quot;FILE&quot; and/or &quot;DB&quot;
  job_loggers:
    - STD_OUTPUT
    - FILE
    # - DB
  # The jobLogger sweeper duration (ignored if `jobLogger` is `stdout`)
  logger_sweeper_duration: 1 #days

notification:
  # Maximum retry count for webhook job
  webhook_job_max_retry: 3
  # HTTP client timeout for webhook job
  webhook_job_http_client_timeout: 3 #seconds

# Log configurations
log:
  # options are debug, info, warning, error, fatal
  level: info
  # configs for logs in local storage
  local:
    # Log files are rotated log_rotate_count times before being removed. If count is 0, old versions are removed rather than rotated.
    rotate_count: 50
    # Log files are rotated only if they grow bigger than log_rotate_size bytes. If size is followed by k, the size is assumed to be in kilobytes.
    # If the M is used, the size is in megabytes, and if G is used, the size is in gigabytes. So size 100, size 100k, size 100M and size 100G
    # are all valid.
    rotate_size: 200M
    # The directory on your host that store log
    location: /var/log/harbor

  # Uncomment following lines to enable external syslog endpoint.
  # external_endpoint:
  #   # protocol used to transmit log to external endpoint, options is tcp or udp
  #   protocol: tcp
  #   # The host of external endpoint
  #   host: localhost
  #   # Port of external endpoint
  #   port: 5140

#This attribute is for migrator to detect the version of the .cfg file, DO NOT MODIFY!
_version: 2.9.0

# Uncomment external_database if using external database.
# external_database:
#   harbor:
#     host: harbor_db_host
#     port: harbor_db_port
#     db_name: harbor_db_name
#     username: harbor_db_username
#     password: harbor_db_password
#     ssl_mode: disable
#     max_idle_conns: 2
#     max_open_conns: 0

# Uncomment redis if need to customize redis db
# redis:
#   # db_index 0 is for core, it's unchangeable
#   # registry_db_index: 1
#   # jobservice_db_index: 2
#   # trivy_db_index: 5
#   # it's optional, the db for harbor business misc, by default is 0, uncomment it if you want to change it.
#   # harbor_db_index: 6
#   # it's optional, the db for harbor cache layer, by default is 0, uncomment it if you want to change it.
#   # cache_db_index: 7

# Uncomment redis if need to customize redis db
# redis:
#   # db_index 0 is for core, it's unchangeable
#   # registry_db_index: 1
#   # jobservice_db_index: 2
#   # trivy_db_index: 5
#   # it's optional, the db for harbor business misc, by default is 0, uncomment it if you want to change it.
#   # harbor_db_index: 6
#   # it's optional, the db for harbor cache layer, by default is 0, uncomment it if you want to change it.
#   # cache_layer_db_index: 7

# Uncomment external_redis if using external Redis server
# external_redis:
#   # support redis, redis+sentinel
#   # host for redis: &lt;host_redis&gt;:&lt;port_redis&gt;
#   # host for redis+sentinel:
#   #  &lt;host_sentinel1&gt;:&lt;port_sentinel1&gt;,&lt;host_sentinel2&gt;:&lt;port_sentinel2&gt;,&lt;host_sentinel3&gt;:&lt;port_sentinel3&gt;
#   host: redis:6379
#   password: 
#   # Redis AUTH command was extended in Redis 6, it is possible to use it in the two-arguments AUTH &lt;username&gt; &lt;password&gt; form.
#   # there's a known issue when using external redis username ref:https://github.com/goharbor/harbor/issues/18892
#   # if you care about the image pull/push performance, please refer to this https://github.com/goharbor/harbor/wiki/Harbor-FAQs#external-redis-username-password-usage
#   # username:
#   # sentinel_master_set must be set to support redis+sentinel
#   #sentinel_master_set:
#   # db_index 0 is for core, it's unchangeable
#   registry_db_index: 1
#   jobservice_db_index: 2
#   trivy_db_index: 5
#   idle_timeout_seconds: 30
#   # it's optional, the db for harbor business misc, by default is 0, uncomment it if you want to change it.
#   # harbor_db_index: 6
#   # it's optional, the db for harbor cache layer, by default is 0, uncomment it if you want to change it.
#   # cache_layer_db_index: 7

# Uncomment uaa for trusting the certificate of uaa instance that is hosted via self-signed cert.
# uaa:
#   ca_file: /path/to/ca

# Global proxy
# Config http proxy for components, e.g. http://my.proxy.com:3128
# Components doesn't need to connect to each others via http proxy.
# Remove component from `components` array if want disable proxy
# for it. If you want use proxy for replication, MUST enable proxy
# for core and jobservice, and set `http_proxy` and `https_proxy`.
# Add domain to the `no_proxy` field, when you want disable proxy
# for some special registry.
proxy:
  http_proxy:
  https_proxy:
  no_proxy:
  components:
    - core
    - jobservice
    - trivy

# metric:
#   enabled: false
#   port: 9090
#   path: /metrics

# Trace related config
# only can enable one trace provider(jaeger or otel) at the same time,
# and when using jaeger as provider, can only enable it with agent mode or collector mode.
# if using jaeger collector mode, uncomment endpoint and uncomment username, password if needed
# if using jaeger agetn mode uncomment agent_host and agent_port
# trace:
#   enabled: true
#   # set sample_rate to 1 if you wanna sampling 100% of trace data; set 0.5 if you wanna sampling 50% of trace data, and so forth
#   sample_rate: 1
#   # # namespace used to differenciate different harbor services
#   # namespace:
#   # # attributes is a key value dict contains user defined attributes used to initialize trace provider
#   # attributes:
#   #   application: harbor
#   # # jaeger should be 1.26 or newer.
#   # jaeger:
#   #   endpoint: http://hostname:14268/api/traces
#   #   username:
#   #   password:
#   #   agent_host: hostname
#   #   # export trace data by jaeger.thrift in compact mode
#   #   agent_port: 6831
#   # otel:
#   #   endpoint: hostname:4318
#   #   url_path: /v1/traces
#   #   compression: false
#   #   insecure: true
#   #   # timeout is in seconds
#   #   timeout: 10

# Enable purge _upload directories
upload_purging:
  enabled: true
  # remove files in _upload directories which exist for a period of time, default is one week.
  age: 168h
  # the interval of the purge operations
  interval: 24h
  dryrun: false

# Cache layer configurations
# If this feature enabled, harbor will cache the resource
# `project/project_metadata/repository/artifact/manifest` in the redis
# which can especially help to improve the performance of high concurrent
# manifest pulling.
# NOTICE
# If you are deploying Harbor in HA mode, make sure that all the harbor
# instances have the same behaviour, all with caching enabled or disabled,
# otherwise it can lead to potential data inconsistency.
cache:
  # not enabled by default
  enabled: false
  # keep cache for one day by default
  expire_hours: 24

# Harbor core configurations
# Uncomment to enable the following harbor core related configuration items.
# core:
#   # The provider for updating project quota(usage), there are 2 options, redis or db,
#   # by default is implemented by db but you can switch the updation via redis which
#   # can improve the performance of high concurrent pushing to the same project,
#   # and reduce the database connections spike and occupies.
#   # By redis will bring up some delay for quota usage updation for display, so only
#   # suggest switch provider to redis if you were ran into the db connections spike aroud
#   # the scenario of high concurrent pushing to same project, no improvment for other scenes.
#   quota_update_provider: redis # Or db

</code></pre>
<hr>
<h2 id="遇到的问题">遇到的问题</h2>
<ol>
<li>权限问题（could not change group /var/run/docker.sock to docker: group docker not found），请用 root 权限执行 docker-compose up -d</li>
</ol>
<pre><code class="language-log">[+] Running 1/0
 ✔ Container harbor  Created                                                                                                 0.0s
Attaching to harbor
harbor  | Certificate request self-signature ok
harbor  | subject=CN = docker:dind server
harbor  | /certs/server/cert.pem: OK
harbor  | Certificate request self-signature ok
harbor  | subject=CN = docker:dind client
harbor  | /certs/client/cert.pem: OK
harbor  | [WARN  tini (12)] Tini is not running as PID 1 and isn't registered as a child subreaper.
harbor  | Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
harbor  | To fix the problem, use the -s option or set the environment variable TINI_SUBREAPER to register Tini as a child subreaper, or run Tini as PID 1.
harbor  | time=&quot;2023-08-30T10:38:50.129710991Z&quot; level=info msg=&quot;Starting up&quot;
harbor  | time=&quot;2023-08-30T10:38:50.131978924Z&quot; level=warning msg=&quot;could not change group /var/run/docker.sock to docker: group docker not found&quot;
harbor  | time=&quot;2023-08-30T10:38:50.132116243Z&quot; level=info msg=&quot;containerd not running, starting managed containerd&quot;
harbor  | failed to start containerd: libcontainerd: failed to save daemon pid to disk: process with PID 57 is still running
harbor  | Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?
harbor exited with code 1
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Jenkins - CI/CD（持续集成、持续交付和持续部署）]]></title>
        <id>https://cainiao1992.github.io/post/jenkins/</id>
        <link href="https://cainiao1992.github.io/post/jenkins/">
        </link>
        <updated>2023-08-29T10:13:40.000Z</updated>
        <content type="html"><![CDATA[<h2 id="docker-compose-安装部署">docker-compose 安装部署</h2>
<pre><code class="language-bash">mkdir jenkins_home
chown -R 1000:1000 ./jenkins_home
</code></pre>
<ul>
<li>docker-compose.yml</li>
</ul>
<pre><code class="language-yaml">version: &quot;3&quot;

services:
  caddy:
    container_name: caddy
    image: caddy:alpine
    restart: unless-stopped
    ports:
      - &quot;80:80&quot;
      - &quot;80:80/udp&quot;
      - &quot;443:443&quot;
      - &quot;443:443/udp&quot;
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile
  jenkins:
    container_name: jenkins
    image: jenkins/jenkins:lts-jdk11
    restart: unless-stopped
    volumes:
      # chown -R 1000:1000 ./jenkins_home
      - ./jenkins_home:/var/jenkins_home
</code></pre>
<ul>
<li>Caddyfile</li>
</ul>
<pre><code class="language-Caddyfile">jenkins.uing.vip {
  log {
    output stdout
    format console
    level  ERROR
  }
  reverse_proxy jenkins:8080
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Portainer - 容器运行监控管理]]></title>
        <id>https://cainiao1992.github.io/post/portainer/</id>
        <link href="https://cainiao1992.github.io/post/portainer/">
        </link>
        <updated>2023-08-29T01:55:00.000Z</updated>
        <content type="html"><![CDATA[<h2 id="docker-compose-安装部署">docker-compose 安装部署</h2>
<ul>
<li>docker-compose.yml</li>
</ul>
<pre><code class="language-yaml">version: &quot;3&quot;

services:
  caddy:
    container_name: caddy
    image: caddy:alpine
    restart: unless-stopped
    ports:
      - &quot;80:80&quot;
      - &quot;80:80/udp&quot;
      - &quot;443:443&quot;
      - &quot;443:443/udp&quot;
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile
  portainer:
    container_name: portainer
    image: portainer/portainer-ce:latest
    command: -H unix:///var/run/docker.sock
    restart: unless-stopped
    # ports:
    #   - 8000:8000
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./portainer:/data

  redis:
    container_name: redis
    image: redis:alpine
    restart: unless-stopped
    volumes:
      - ./redis:/data
</code></pre>
<ul>
<li>Caddyfile</li>
</ul>
<pre><code class="language-Caddyfile">portainer.uing.vip {
  log {
    output stdout
    format console
    level  ERROR
  }
  reverse_proxy portainer:9000
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Gitea - 代码项目管理]]></title>
        <id>https://cainiao1992.github.io/post/gitea/</id>
        <link href="https://cainiao1992.github.io/post/gitea/">
        </link>
        <updated>2023-08-26T21:00:45.000Z</updated>
        <content type="html"><![CDATA[<h1 id="gitea-安装部署">Gitea 安装部署</h1>
<h2 id="配置-ssh-直通可选不需要-ssh-协议同步无需此步骤可以使用-httpshttp-协议同步代替">配置 SSH 直通（可选，不需要 SSH 协议同步无需此步骤，可以使用 https/http 协议同步代替）</h2>
<pre><code class="language-bash"># 记录下 UID/GID 替换中的 USER_UID USER_GID
sudo adduser --system --shell /bin/bash --gecos 'Git Version Control' --group --disabled-password --home /home/git git
# 生成 SSH 密钥对
sudo -u git ssh-keygen -t rsa -b 4096 -C &quot;Gitea Host Key&quot;

# ----------------------------------------------------------------

sudo -u git cat /home/git/.ssh/id_rsa.pub | sudo -u git tee -a /home/git/.ssh/authorized_keys
sudo -u git chmod 600 /home/git/.ssh/authorized_keys

cat &lt;&lt;&quot;EOF&quot; | sudo tee /usr/local/bin/gitea
#!/bin/sh
ssh -p 2222 -o StrictHostKeyChecking=no git@127.0.0.1 &quot;SSH_ORIGINAL_COMMAND=\&quot;$SSH_ORIGINAL_COMMAND\&quot; $0 $@&quot;
EOF
sudo chmod +x /usr/local/bin/gitea
</code></pre>
<h2 id="docker-compose-安装部署">docker-compose 安装部署</h2>
<ul>
<li>docker-compose.yml</li>
</ul>
<pre><code class="language-yaml">version: &quot;3&quot;

services:
  caddy:
    container_name: caddy
    image: caddy:alpine
    restart: unless-stopped
    ports:
      - &quot;80:80&quot;
      - &quot;80:80/udp&quot;
      - &quot;443:443&quot;
      - &quot;443:443/udp&quot;
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile
  gitea:
    container_name: gitea
    image: gitea/gitea:latest
    restart: unless-stopped
    # depends_on:
    #   - redis
    environment:
      - USER=git
      - USER_UID=111
      - USER_GID=122
    volumes:
      - ./gitea:/data
      - /home/git/.ssh:/data/git/.ssh
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    ports:
      - &quot;127.0.0.1:2222:22&quot;


  # redis:
  #   container_name: redis
  #   image: redis:alpine
  #   restart: unless-stopped
  #   volumes:
  #     - ./redis:/data
</code></pre>
<ul>
<li>Caddyfile</li>
</ul>
<pre><code class="language-Caddyfile">:80 {
  redir https://{host}{uri}
}
gitea.uing.vip {
  log {
    output stdout
    format console
    level  ERROR
  }
  reverse_proxy gitea:3000
}
</code></pre>
<h2 id="启用-gitea-actions-内置的-cicd-持续集成-持续交付和持续部署解决方案">启用 Gitea Actions 内置的 CI/CD （持续集成、持续交付和持续部署）解决方案</h2>
<h3 id="配置-gitea-服务器">配置 Gitea 服务器</h3>
<pre><code class="language-bash">cat &lt;&lt; EOF &gt;&gt; gitea/gitea/conf/app.ini
[actions]
ENABLED=true
EOF
docker-compose restart gitea
</code></pre>
<h3 id="生成-gitea-runner-配置文件">生成  Gitea Runner 配置文件</h3>
<pre><code>mkdir gitea_runner &amp;&amp; cd gitea_runner
docker run --entrypoint=&quot;&quot; --rm -it gitea/act_runner:latest act_runner generate-config &gt; config.yaml
</code></pre>
<h3 id="docker-compose-安装-gitea-runner-部署">docker-compose 安装 Gitea Runner 部署</h3>
<ul>
<li>docker-compose.yml</li>
</ul>
<pre><code class="language-yaml">version: &quot;3&quot;

services:
  gitea_runner:
    container_name: gitea_runner
    image: gitea/act_runner:latest
    # 如果使用服务器容器名称作为 URL HOST 的话，需要先启动 Gitea
    depends_on:
      - gitea
    environment:
      CONFIG_FILE: /config.yaml
      # Gitea 服务器地址（也可以是内网地址或者容器内部地址）
      GITEA_INSTANCE_URL: https://gitea.uing.vip
      # 获取地址 https://gitea.uing.vip/admin/actions/runners/
      GITEA_RUNNER_REGISTRATION_TOKEN: &quot;&quot;
      # Runner名称（可选）。如果留空，将使用主机名
      GITEA_RUNNER_NAME: &quot;&quot;
      GITEA_RUNNER_LABELS: &quot;&quot;
    volumes:
      - ./gitea_runner/config.yaml:/config.yaml
      - ./gitea_runner/data:/data
      - /var/run/docker.sock:/var/run/docker.sock
</code></pre>
<h2 id="配置仓库启用-gitea-actions">配置仓库启用 Gitea Actions</h2>
<ol>
<li>打开仓库设置 https://gitea.uing.vip/&lt;owner&gt;/&lt;repo&gt;/settings</li>
<li>找到并勾选 <strong>启用 Actions</strong> ，并 <strong>更新仓库设置</strong> 保存设置<br>
<img src="https://cainiao1992.github.io/post-images/1693367900388.png" alt="enable_actions" loading="lazy"></li>
<li>在仓库代码下新建目录 <strong>.gitea/workflows/</strong>，新建 Yaml 文件编写 Gitea Actions 执行代码</li>
</ol>
<pre><code class="language-bash">git clone git@gitea.uing.vip:cainiao/gitea_runner.git

cd gitea_runner &amp;&amp; mkdir -p .gitea/workflows/

cat &lt;&lt;&quot;EOF&quot; &gt; .gitea/workflows/demo.yaml
name: Gitea Actions Demo
run-name: ${{ gitea.actor }} is testing out Gitea Actions 🚀
on: [push]

jobs:
  Explore-Gitea-Actions:
    runs-on: ubuntu-latest
    steps:
      - run: echo &quot;🎉 The job was automatically triggered by a ${{ gitea.event_name }} event.&quot;
      - run: echo &quot;🐧 This job is now running on a ${{ runner.os }} server hosted by Gitea!&quot;
      - run: echo &quot;🔎 The name of your branch is ${{ gitea.ref }} and your repository is ${{ gitea.repository }}.&quot;
      - name: Check out repository code
        uses: actions/checkout@v3
      - run: echo &quot;💡 The ${{ gitea.repository }} repository has been cloned to the runner.&quot;
      - run: echo &quot;🖥️ The workflow is now ready to test your code on the runner.&quot;
      - name: List files in the repository
        run: |
          ls ${{ gitea.workspace }}
      - run: echo &quot;🍏 This job's status is ${{ job.status }}.&quot;
EOF

git add .gitea/workflows/demo.yaml
git commit -m &quot;add .gitea/workflows/demo.yaml&quot;
git push
</code></pre>
<ol start="4">
<li>在仓库的 Actions 下查看到执行过程及结果：https://gitea.uing.vip/&lt;owner&gt;/&lt;repo&gt;/actions</li>
</ol>
<h2 id="相关连接">相关连接</h2>
<ul>
<li>(Configuration Cheat Sheet)[https://docs.gitea.com/administration/config-cheat-sheet]</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Git 使用笔记]]></title>
        <id>https://cainiao1992.github.io/post/git/</id>
        <link href="https://cainiao1992.github.io/post/git/">
        </link>
        <updated>2023-08-17T08:59:29.000Z</updated>
        <content type="html"><![CDATA[<h1 id="git-使用笔记">Git 使用笔记</h1>
<h2 id="从主仓库更新代码到-fork-仓库">从主仓库更新代码到 fork 仓库</h2>
<pre><code class="language-shell">git remote -v
git remote add github https://github.com/chenxiangfang/Main.git
git fetch github
git merge github/master
git push
</code></pre>
<h2 id="从-github-中拉取变更同步到本地并提交到-fork-仓库">从 github 中拉取变更同步到本地，并提交到 fork 仓库</h2>
<pre><code class="language-shell">git fetch github
git merge github/master
git push
git fetch github --all
git push origin --all
</code></pre>
<h2 id="配置-git-提交时的邮箱和用户名">配置 Git 提交时的邮箱和用户名</h2>
<pre><code class="language-shell"># 全局修改
git config --global user.email &quot;565499699@qq.com&quot;
git config --global user.name &quot;Xiangfang Chen&quot;
# 当前仓库修改
git config user.email &quot;565499699@qq.com&quot;
git config user.name &quot;Xiangfang Chen&quot;
</code></pre>
<h2 id="设置-httphttps-免密登录git-clone-第二次不需要再次输入密码了">设置 HTTP/HTTPS 免密登录（git clone 第二次不需要再次输入密码了）</h2>
<pre><code class="language-bash">git config --global credential.helper store
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[CentOS]]></title>
        <id>https://cainiao1992.github.io/post/centos/</id>
        <link href="https://cainiao1992.github.io/post/centos/">
        </link>
        <updated>2023-08-17T08:54:11.000Z</updated>
        <content type="html"><![CDATA[<h2 id="centos-7-网络配置">CentOS 7 网络配置</h2>
<pre><code class="language-shell"># 网络配置
sed -i 's/ONBOOT=&quot;no&quot;/ONBOOT=&quot;yes&quot;/g' /etc/sysconfig/network-scripts/ifcfg-eth0
sed -i 's/IPV6INIT=&quot;yes&quot;/IPV6INIT=&quot;no&quot;/g' /etc/sysconfig/network-scripts/ifcfg-eth0
sed -i 's/BOOTPROTO=&quot;dhcp&quot;/BOOTPROTO=&quot;none&quot;/g' /etc/sysconfig/network-scripts/ifcfg-eth0

sed -i 's/ONBOOT=no/ONBOOT=yes/g' /etc/sysconfig/network-scripts/ifcfg-eth0
sed -i 's/IPV6INIT=yes/IPV6INIT=no/g' /etc/sysconfig/network-scripts/ifcfg-eth0
sed -i 's/BOOTPROTO=dhcp/BOOTPROTO=none/g' /etc/sysconfig/network-scripts/ifcfg-eth0

cat &lt;&lt; EOF &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-eth0
IPADDR=192.168.2.23
PREFIX=16
GATEWAY=192.168.1.1
DNS1=114.114.114.114
DNS2=192.168.1.1
EOF
cat &lt;&lt; EOF &gt;/etc/hostname
QRadarCE
EOF
</code></pre>
<h2 id="centos-7-安装必备包">CentOS 7 安装必备包</h2>
<pre><code class="language-shell"># 必备软件
yum install -y epel-release
yum update -y
yum install -y bash-completion bash-completion-extras sudo openssh-server
systemctl enable sshd
systemctl start sshd
ln -s -f /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
reboot
</code></pre>
<h2 id="centos-6-安装必备包">CentOS 6 安装必备包</h2>
<pre><code class="language-shell">mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup
curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-vault-6.10.repo
yum clean all &amp;&amp; yum makecache
yum install -y epel-release
yum update -y
yum install -y bash-completion bash-completion-extras sudo openssh-server
echo &quot;PermitRootLogin yes&quot; | tee /etc/ssh/sshd_config

ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key
ssh-keygen -t dsa -f /etc/ssh/ssh_host_dsa_key
ssh-keygen -t ecdsa -f /etc/ssh/ssh_host_ecdsa_key
ssh-keygen -t ed25519 -f /etc/ssh/ssh_host_ed25519_key

chkconfig sshd on
service sshd start
ln -s -f /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
</code></pre>
<h2 id="extra-packages-for-enterprise-linux-epel">Extra Packages for Enterprise Linux (EPEL)</h2>
<pre><code class="language-shell">yum install -y epel-release
</code></pre>
<h2 id="elrepo-project">ELRepo Project</h2>
<p>Import the public key:</p>
<pre><code class="language-shell">rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org
</code></pre>
<p>To install ELRepo for RHEL-9:</p>
<pre><code class="language-bash">yum install https://www.elrepo.org/elrepo-release-9.el9.elrepo.noarch.rpm
</code></pre>
<p>To install ELRepo for RHEL-8:</p>
<pre><code class="language-shell">yum install https://www.elrepo.org/elrepo-release-8.el8.elrepo.noarch.rpm
</code></pre>
<p>To install ELRepo for RHEL-7, SL-7 or CentOS-7:</p>
<pre><code class="language-shell">yum install https://www.elrepo.org/elrepo-release-7.el7.elrepo.noarch.rpm
</code></pre>
<p>安装长期支持内核（lt = long time）</p>
<pre><code class="language-shell">yum --enablerepo=elrepo-kernel -y install kernel-lt
</code></pre>
<p>安装稳定主线内核kernel-ml（ml=mainline）</p>
<pre><code class="language-shell">yum --enablerepo=elrepo-kernel -y install kernel-ml
</code></pre>
<h3 id="红帽软件集合">红帽软件集合</h3>
<p>https://access.redhat.com/support/policy/updates/rhscl-rhel7</p>
<pre><code class="language-shell">yum install centos-release-scl –y
</code></pre>
<p>安装 GCC 9</p>
<pre><code class="language-shell">yum install devtoolset-9-toolchain –y
# 临时使用
scl enable devtoolset-9 bash
source scl_source enable devtoolset-9

安装 GCC 7
```shell
yum install devtoolset-7-toolchain –y
# 临时使用
scl enable devtoolset-7 bash
source scl_source enable devtoolset-7
</code></pre>
<p>安装 Python 3.8</p>
<pre><code class="language-shell">yum install rh-python38 rh-python38-python-devel –y
# 临时使用
scl enable rh-python38 bash
source scl_source enable rh-python38
</code></pre>
<h2 id="mysql-server-57">MySQL Server 5.7</h2>
<pre><code class="language-shell">yum install -y http://repo.mysql.com/mysql57-community-release-el7.rpm
rpm -import http://repo.mysql.com/RPM-GPG-KEY-mysql-2022

yum install mysql-server -y

systemctl enable mysqld
systemctl start mysqld

grep 'temporary password'  /var/log/mysqld.log
</code></pre>
<h2 id="mysql-server-80">MySQL Server 8.0</h2>
<pre><code class="language-shell">yum install -y https://repo.mysql.com/mysql80-community-release-el7.rpm
rpm -import http://repo.mysql.com/RPM-GPG-KEY-mysql-2022

yum install mysql-server -y

systemctl enable mysqld
systemctl start mysqld

grep 'temporary password'  /var/log/mysqld.log
</code></pre>
<h2 id="nginx">Nginx</h2>
<pre><code class="language-shell">yum install -y https://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm
yum install -y nginx
systemctl enable nginx
systemctl start nginx
</code></pre>
<h2 id="redis-32">Redis 3.2</h2>
<pre><code class="language-shell">yum install -y redis
systemctl enable redis
systemctl start redis
</code></pre>
<h2 id="redis-6">Redis 6</h2>
<pre><code class="language-shell">yum install -y \
https://repo.ius.io/ius-release-el7.rpm \
https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm
yum install -y redis6
systemctl enable redis
systemctl start redis
</code></pre>
<h2 id="openjdk">OpenJDK</h2>
<pre><code class="language-shell"># openjdk 8
yum install -y java-1.8.0-openjdk java-1.8.0-openjdk-devel

# openjdk 11
yum install -y java-11-openjdk java-11-openjdk-devel
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[卸载云服务监控]]></title>
        <id>https://cainiao1992.github.io/post/uninstall-cloud-server-monitor/</id>
        <link href="https://cainiao1992.github.io/post/uninstall-cloud-server-monitor/">
        </link>
        <updated>2023-08-17T08:45:14.000Z</updated>
        <content type="html"><![CDATA[<h2 id="aliyun">AliYun</h2>
<pre><code class="language-bash"># 卸载云盾（安骑士）
curl http://update.aegis.aliyun.com/download/uninstall.sh | bash
curl http://update.aegis.aliyun.com/download/quartz_uninstall.sh | bash

sudo rm -r /usr/local/aegis
sudo systemctl disable aliyun.service
sudo rm /usr/sbin/aliyun-service
sudo rm /usr/sbin/aliyun-service.backup
sudo rm /usr/sbin/aliyun_installer
sudo rm /etc/systemd/system/aliyun.service
sudo rm /lib/systemd/system/aliyun.service

# 卸载云助手Agent
/usr/local/share/assist-daemon/assist_daemon --stop
/usr/local/share/assist-daemon/assist_daemon --delete
rm -rf /usr/local/share/assist-daemon

systemctl stop aliyun.service
apt remove  aliyun-assist -y
dpkg -l |grep &quot;^rc&quot;|awk '{print $2}'|sudo xargs apt -y purge
rm -rf /usr/local/share/aliyun-assist
</code></pre>
<blockquote>
<p>云监控</p>
</blockquote>
<pre><code class="language-bash"># 卸载云监控 Go 语言版
# 停止
/usr/local/cloudmonitor/CmsGoAgent.linux-* stop
# 从系统服务中移除
/usr/local/cloudmonitor/CmsGoAgent.linux-* uninstall

# 卸载
/usr/local/cloudmonitor/CmsGoAgent.linux-* stop &amp;&amp; \
/usr/local/cloudmonitor/CmsGoAgent.linux-* uninstall &amp;&amp; \
rm -rf /usr/local/cloudmonitor

# 卸载云监控 Java 版
# 停止
/usr/local/cloudmonitor/wrapper/bin/cloudmonitor.sh stop

# 卸载
/usr/local/cloudmonitor/wrapper/bin/cloudmonitor.sh remove &amp;&amp; \
rm -rf /usr/local/cloudmonitor
</code></pre>
<h2 id="qcloud">QCloud</h2>
<pre><code class="language-bash">/usr/local/qcloud/stargate/admin/stop.sh
/usr/local/qcloud/YunJing/stopYDCore.sh
/usr/local/qcloud/monitor/barad/admin/stop.sh

/usr/local/qcloud/stargate/admin/uninstall.sh
/usr/local/qcloud/YunJing/uninst.sh
/usr/local/qcloud/monitor/barad/admin/uninstall.sh
rm -rf /usr/local/qcloud
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[初始化 VPS]]></title>
        <id>https://cainiao1992.github.io/post/initialize-the-vps/</id>
        <link href="https://cainiao1992.github.io/post/initialize-the-vps/">
        </link>
        <updated>2023-08-17T08:21:02.000Z</updated>
        <content type="html"><![CDATA[<h1 id="ubuntu">Ubuntu</h1>
<h2 id="基础操作">基础操作</h2>
<h3 id="客户端">客户端</h3>
<pre><code class="language-bash"># 配置免密登录
ssh-copy-id root@uing.vip
</code></pre>
<h3 id="服务器">服务器</h3>
<pre><code class="language-bash">apt update &amp;&amp; apt -o Dpkg::Options::=&quot;--force-confnew&quot; full-upgrade -y &amp;&amp; apt autoremove -y
apt install -y curl htop vim ufw sudo bash-completion

cat &gt;&gt; /etc/security/limits.conf &lt;&lt; EOF
# End of file
*     soft   nofile    655360
*     hard   nofile    655360
*     soft   nproc     655360
*     hard   nproc     655360
*     soft   core      655360
*     hard   core      655360
*     hard   memlock   unlimited
*     soft   memlock   unlimited
EOF

cat &gt;&gt; /etc/sysctl.conf &lt;&lt; EOF
net.core.rmem_max=33554432
net.core.wmem_max=33554432
net.core.default_qdisc=fq
net.ipv4.tcp_congestion_control=bbr
EOF
sysctl -p

cat &gt; /etc/hostname &lt;&lt; EOF
uing.vip
EOF
cat &gt;&gt; /etc/hosts &lt;&lt; EOF
127.0.1.1 uing.vip
EOF

# 设置上海时区
ln -s -f /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
timedatectl set-timezone Asia/Shanghai

# 防火墙配置
ufw default deny
ufw allow ssh
ufw allow http
ufw allow https
ufw allow 443/udp
ufw enable

# 重启
reboot

# Certbot HTTPS 证书安装续订
apt install -y certbot
certbot certonly --standalone --agree-tos --register-unsafely-without-email -d uing.vip
</code></pre>
<h2 id="安装-docker">安装 Docker</h2>
<pre><code class="language-bash">curl https://get.docker.com/ | sh
ln -s /usr/libexec/docker/cli-plugins/docker-compose /usr/local/bin/docker-compose
# 更方便使用 docker exec 命令
sudo tee /usr/local/bin/dssh &gt; /dev/null &lt;&lt; EOF
#!/bin/sh
docker exec -it \$1 sh
EOF
sudo chmod a+x /usr/local/bin/dssh

# 让 Docker 支持 IPv6
sudo tee /etc/docker/daemon.json &gt; /dev/null &lt;&lt; EOF
{
  &quot;ipv6&quot;: true,
  &quot;fixed-cidr-v6&quot;: &quot;2001:db8:1::/64&quot;,
  &quot;experimental&quot;: true,
  &quot;ip6tables&quot;: true
}
EOF
sudo systemctl restart docker

# 创建 Docker VPS 容器网络
docker network create \
  --driver=bridge \
  --subnet=172.16.1.0/24 \
  --ip-range=172.16.1.0/24 \
  --gateway=172.16.1.1 \
  vps

# 支持 IPv6
docker network create \
  --driver=bridge \
  --ipv6 \
  --subnet=172.16.1.0/24 \
  --ip-range=172.16.1.0/24 \
  --gateway=172.16.1.1 \
  --subnet=2001:0DB8::1:0/112 \
  --ip-range2001:0DB8::1:0/112 \
  --gateway=2001:db8::1:1 \
  vps
</code></pre>
]]></content>
    </entry>
</feed>